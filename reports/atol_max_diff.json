{
  "adamlin/ml999_explosion_proof_electrical_equipment": 0.03529989719390869,
  "begar/xlm-roberta-base-finetuned-marc": 0.028858482837677002,
  "unicamp-dl/mMiniLM-L6-v2-pt-msmarco-v1": 0.028439998626708984,
  "o2poi/sst2-eda-albert": 0.02487015724182129,
  "lewtun/xlm-roberta-base-finetuned-marc-en": 0.02174222469329834,
  "avichr/heBERT_sentiment_analysis": 0.019390106201171875,
  "lamhieu/distilbert-base-multilingual-cased-vietnamese-topicifier": 0.01837158203125,
  "bvanaken/CORe-clinical-diagnosis-prediction": 0.017766505479812622,
  "Pratibha/xlm-roberta-base-finetuned-marc-en": 0.014308571815490723,
  "ashish-chouhan/xlm-roberta-base-finetuned-marc": 0.014244437217712402,
  "yaoyinnan/bert-base-chinese-covid19": 0.013215065002441406,
  "liam168/c2-roberta-base-finetuned-dianping-chinese": 0.01267021894454956,
  "peter2000/xlm-roberta-base-finetuned-ecoicop": 0.011878013610839844,
  "finiteautomata/beto-sentiment-analysis": 0.011621356010437012,
  "ibraheemmoosa/xlmindic-base-multiscript-soham": 0.01042698323726654,
  "pablouribe/beto-copus-overfitted": 0.010421216487884521,
  "jaesun/distilbert-base-uncased-finetuned-cola": 0.009926021099090576,
  "pablouribe/beto-copus": 0.009825706481933594,
  "tals/albert-base-vitaminc": 0.00971078872680664,
  "m3hrdadfi/albert-fa-base-v2-sentiment-multi": 0.009689509868621826,
  "m3hrdadfi/albert-fa-base-v2-clf-persiannews": 0.008346319198608398,
  "w11wo/indonesian-roberta-base-indolem-sentiment-classifier-fold-1": 0.008185476064682007,
  "textattack/albert-base-v2-RTE": 0.00736469030380249,
  "danwilbury/xlm-roberta-base-finetuned-marc-en": 0.007308363914489746,
  "benjaminbeilharz/distilbert-base-uncased-empatheticdialogues-sentiment-classifier": 0.006794929504394531,
  "adamlin/ml999_power_stacker": 0.006620526313781738,
  "veronica320/SPTE_roberta-large-mnli_all": 0.00654418021440506,
  "Kayvane/distilvert-complaints-subproduct": 0.006510734558105469,
  "elozano/tweet_emotion_eval": 0.00644528865814209,
  "anirudh21/distilbert-base-uncased-finetuned-cola": 0.006362438201904297,
  "pablouribe/beto-copus-supercategories": 0.006268978118896484,
  "sismetanin/rubert_conversational-ru-sentiment-rureviews": 0.006007969379425049,
  "m3hrdadfi/bert-fa-base-uncased-wikinli": 0.005945742130279541,
  "projecte-aina/roberta-base-ca-cased-tc": 0.0058144330978393555,
  "ayameRushia/roberta-base-indonesian-sentiment-analysis-smsa": 0.0057604312896728516,
  "phailyoor/distilbert-base-uncased-finetuned-yahd": 0.005749702453613281,
  "paintingpeter/distilbert-base-uncased-distilled-clinc": 0.0057334303855896,
  "d4niel92/xlm-roberta-base-finetuned-marc-en": 0.005731344223022461,
  "SongRb/distilbert-base-uncased-finetuned-cola": 0.005531132221221924,
  "LeoFeng/ChineseSequenceClassification": 0.0055027008056640625,
  "benjaminbeilharz/bert-base-uncased-empatheticdialogues-sentiment-classifier": 0.005499839782714844,
  "sciarrilli/distilbert-base-uncased-cola": 0.0054694414138793945,
  "mohsenfayyaz/albert-base-v2-offenseval2019-downsample": 0.005457878112792969,
  "sgugger/bert-fine-tuned-cola": 0.005421161651611328,
  "CAMeL-Lab/bert-base-arabic-camelbert-mix-did-madar-corpus26": 0.005389213562011719,
  "Alireza1044/albert-base-v2-cola": 0.005338907241821289,
  "ianporada/roberta_base_plausibility": 0.005271434783935547,
  "orisuchy/Descriptive_Classifier": 0.005170583724975586,
  "julien-c/reactiongif-roberta": 0.0050814151763916016,
  "mgrella/autonlp-bank-transaction-classification-5521155": 0.0050506591796875,
  "aditeyabaral/finetuned-iitp_pdt_review-additionalpretrained-xlm-roberta-base": 0.005049943923950195,
  "cross-encoder/quora-roberta-base": 0.004985809326171875,
  "navteca/quora-roberta-base": 0.004985809326171875,
  "bhadresh-savani/albert-base-v2-emotion": 0.004938721656799316,
  "Alireza1044/albert-base-v2-sst2": 0.004883289337158203,
  "Jeska/VaccinChatSentenceClassifierDutch_fromBERTje2_DAdialogQonly": 0.004845619201660156,
  "aditeyabaral/finetuned-iitp_pdt_review-xlm-roberta-base": 0.004726529121398926,
  "DaNLP/da-xlmr-ned": 0.004510402679443359,
  "adamlin/text-cls": 0.004471130669116974,
  "mattchurgin/distilbert-mrpc": 0.004446297883987427,
  "ZiweiG/ziwei-bert-imdb": 0.004431486129760742,
  "textattack/albert-base-v2-rotten-tomatoes": 0.004423379898071289,
  "m3hrdadfi/albert-fa-base-v2-sentiment-binary": 0.0044138431549072266,
  "textattack/albert-base-v2-imdb": 0.0043544769287109375,
  "textattack/albert-base-v2-MRPC": 0.004345715045928955,
  "harish/PT-UP-xlmR-OneShot-FalseTrue-0_2_BEST": 0.004297152161598206,
  "bgoel4132/twitter-sentiment": 0.004277706146240234,
  "philschmid/RoBERTa-Banking77": 0.004192352294921875,
  "Sakil/imdbsentdistilbertmodel": 0.004181206226348877,
  "laurauzcategui/xlm-roberta-base-finetuned-marc-en": 0.0041747987270355225,
  "SetFit/distilbert-base-uncased__enron_spam__all-train": 0.004127860069274902,
  "Kayvane/distilbert-complaints-product": 0.0040912628173828125,
  "claudio75/xlm-roberta-base-finetuned-marc": 0.004091024398803711,
  "cross-encoder/ms-marco-MiniLM-L-12-v2": 0.00408172607421875,
  "anirudh21/albert-large-v2-finetuned-mrpc": 0.00407862663269043,
  "maximedb/autonlp-vaccinchat-22134694": 0.004012584686279297,
  "rti-international/rota": 0.003983020782470703,
  "nickmuchi/minilm-finetuned-emotion_nm": 0.003976225852966309,
  "cvcio/mediawatch-el-topics": 0.003958225250244141,
  "saattrupdan/verdict-classifier": 0.003928184509277344,
  "ayameRushia/roberta-base-indonesian-1.5G-sentiment-analysis-smsa": 0.003925323486328125,
  "unicamp-dl/mMiniLM-L6-v2-en-pt-msmarco-v1": 0.003923654556274414,
  "ayameRushia/indobert-base-uncased-finetuned-indonlu-smsa": 0.0039030909538269043,
  "shokiokita/distilbert-base-uncased-finetuned-cola": 0.003877878189086914,
  "JBNLRY/distilbert-base-uncased-finetuned-cola": 0.0038735568523406982,
  "MKaan/multilingual-cpv-sector-classifier": 0.0038726329803466797,
  "veronica320/SPTE_disjoint_adjs_roberta-large-mnli_200": 0.003859877586364746,
  "jimmyliao/distilbert-base-uncased-finetuned-cola": 0.003846287727355957,
  "erst/xlm-roberta-base-finetuned-db07": 0.0037698745727539062,
  "aditeyabaral/finetuned-sail2017-additionalpretrained-distilbert-base-cased": 0.0037370026111602783,
  "Newtral/xlm-r-finetuned-toxic-political-tweets-es": 0.0037309229373931885,
  "cross-encoder/nli-roberta-base": 0.00370633602142334,
  "textattack/albert-base-v2-yelp-polarity": 0.0036973506212234497,
  "unicamp-dl/mMiniLM-L6-v2-mmarco-v2": 0.0036804676055908203,
  "m3hrdadfi/albert-fa-base-v2-clf-digimag": 0.0036661624908447266,
  "anditya/xlm-roberta-base-finetuned-marc-en": 0.0036650896072387695,
  "aXhyra/emotion_trained_final": 0.0036634206771850586,
  "RameshArvind/roberta_long_answer_nq": 0.003620147705078125,
  "NaliniK/distilbert-base-uncased-finetuned-cola": 0.0036056041717529297,
  "unicamp-dl/mMiniLM-L6-v2-pt-v2": 0.0035948753356933594,
  "cross-encoder/msmarco-MiniLM-L12-en-de-v1": 0.003592967987060547,
  "philschmid/BERT-Banking77": 0.0035921335220336914,
  "projecte-aina/roberta-base-ca-cased-te": 0.0035830140113830566,
  "spentaur/post-here": 0.00353240966796875,
  "ibraheemmoosa/xlmindic-base-uniscript-soham": 0.0035295486450195312,
  "nicktien/TaipeiQA_v1": 0.0035189390182495117,
  "Cameron/BERT-eec-emotion": 0.003491699695587158,
  "mollypak/cardiff-num": 0.0034027099609375,
  "m3hrdadfi/zabanshenas-roberta-base-mix": 0.003393888473510742,
  "abdelkader/distilbert-base-uncased-distilled-clinc": 0.0033707618713378906,
  "aXhyra/irony_trained_final": 0.0033702850341796875,
  "sismetanin/rubert_conversational-ru-sentiment-rusentiment": 0.00333404541015625,
  "BaptisteDoyen/camembert-base-xnli": 0.0033127665519714355,
  "hoonst/distilbert-base-uncased-finetuned-cola": 0.003270387649536133,
  "remotejob/gradientclassification_v0": 0.003268003463745117,
  "nikunjbjj/jd-resume-model": 0.003252323716878891,
  "rg089/bert_newspaper_source": 0.003237992525100708,
  "cointegrated/rubert-tiny2-cedr-emotion-detection": 0.003214597702026367,
  "CAMeL-Lab/bert-base-arabic-camelbert-ca-sentiment": 0.003195628523826599,
  "w11wo/indonesian-roberta-base-indolem-sentiment-classifier-fold-0": 0.0031633377075195312,
  "cross-encoder/quora-distilroberta-base": 0.0031609535217285156,
  "mofawzy/bert-arsentd-lev": 0.003149956464767456,
  "mollypak/cardiff": 0.00312042236328125,
  "vishnun/bert-base-cased-tamil-mix-sentiment": 0.0031118392944335938,
  "peter2000/xlm-roberta-base-finetuned-marc-en": 0.0030968189239501953,
  "sampathkethineedi/industry-classification": 0.003093719482421875,
  "Krassy/xlm-roberta-base-finetuned-marc-en": 0.003092348575592041,
  "bergum/xtremedistil-l6-h384-emotion": 0.00308150053024292,
  "phailyoor/distilbert-base-uncased-finetuned-yahd-2": 0.0030726194381713867,
  "sampathkethineedi/industry-classification-api": 0.0030579566955566406,
  "M47Labs/arabert_multiclass_news": 0.0030333995819091797,
  "harish/PT-UP-xlmR-ContextIncluded_IdiomExcluded-FewShot-4_BEST": 0.003023803234100342,
  "celtics1863/env-bert-topic": 0.0030001401901245117,
  "yigitbekir/turkish-bert-uncased-sentiment": 0.002978086471557617,
  "pertschuk/albert-base-quora-classifier": 0.0029594898223876953,
  "gauravtripathy/distilbert-base-uncased-finetuned-cola": 0.0029489994049072266,
  "saattrupdan/verdict-classifier-en": 0.0029397010803222656,
  "cross-encoder/qnli-distilroberta-base": 0.0029326677322387695,
  "CleveGreen/JobClassifier_v2": 0.002920866012573242,
  "divyshah/text-categorization": 0.002914905548095703,
  "TehranNLP-org/albert-base-v2-avg-mnli": 0.002884984016418457,
  "anirudh21/bert-base-uncased-finetuned-cola": 0.0028838515281677246,
  "danlou/distilbert-base-uncased-finetuned-cola": 0.002863258123397827,
  "obsei-ai/sell-buy-intent-classifier-bert-mini": 0.002855956554412842,
  "textattack/albert-base-v2-SST-2": 0.0028314590454101562,
  "emekaboris/autonlp-txc-17923129": 0.0028243064880371094,
  "fadhilarkan/distilbert-base-uncased-finetuned-cola-3": 0.002805650234222412,
  "ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa": 0.002805471420288086,
  "ismaelardo/BETO_3d": 0.0027985572814941406,
  "mrm8488/distilroberta-finetuned-tweets-hate-speech": 0.0027976036071777344,
  "AlekseyDorkin/xlm-roberta-en-ru-emoji": 0.002792835235595703,
  "alecmullen/autonlp-group-classification-441411446": 0.0027875900268554688,
  "athar/distilbert-base-uncased-finetuned-cola": 0.002767205238342285,
  "hchc/distilbert-base-uncased-finetuned-cola": 0.002767205238342285,
  "philschmid/bert-mini-sst2-distilled": 0.0027632713317871094,
  "benjaminbeilharz/distilbert-base-uncased-next-turn-classifier": 0.0027370452880859375,
  "Ajay191191/autonlp-Test-530014983": 0.0027235746383666992,
  "Hinova/distilbert-base-uncased-finetuned-cola": 0.0027057528495788574,
  "blanchefort/rubert-base-cased-sentiment-med": 0.0026903152465820312,
  "mollypak/bert-model-full-cardiff": 0.0026874542236328125,
  "typeform/distilbert-base-uncased-mnli": 0.0026866793632507324,
  "blackbird/alberta-base-mnli-v1": 0.002682328224182129,
  "lewtun/xlm-roberta-base-finetuned-marc-en-dummy": 0.002682209014892578,
  "m3hrdadfi/albert-fa-base-v2-sentiment-digikala": 0.0026601552963256836,
  "harish/EN-AStitchTask1A-DistilBERT-FalseTrue-0-2-BEST": 0.0026589632034301758,
  "harish/EN-AStitchTask1A-RoBERTaBase-FalseTrue-0-0-BEST": 0.002653837203979492,
  "w11wo/indonesian-roberta-base-indolem-sentiment-classifier-fold-4": 0.002648591995239258,
  "MINYOUNG/distilbert-base-uncased-finetuned-cola": 0.002645730972290039,
  "JonatanGk/roberta-base-ca-finetuned-tecla": 0.0026297569274902344,
  "Jush/autonlp-bp-29016523": 0.0026276111602783203,
  "lucasresck/bert-base-cased-ag-news": 0.002626091241836548,
  "unicamp-dl/mMiniLM-L6-v2-en-pt-msmarco-v2": 0.0025873184204101562,
  "mrm8488/camembert-base-finetuned-pawsx-fr": 0.0025815963745117188,
  "cross-encoder/msmarco-MiniLM-L6-en-de-v1": 0.0025801658630371094,
  "Emily/fyp": 0.00257110595703125,
  "Kayvane/distilbert-undersampled-noweights": 0.0025348663330078125,
  "anirudh21/albert-base-v2-finetuned-qnli": 0.0025295019149780273,
  "ttajun/bert_nm70k_posneg01": 0.0025281906127929688,
  "serdarakyol/interpress-turkish-news-classification": 0.002512693405151367,
  "Kayvane/distilbert-undersampled": 0.0025048255920410156,
  "blizrys/distilbert-base-uncased-finetuned-cola": 0.002492755651473999,
  "caioamb/distilbert-base-uncased-finetuned-cola": 0.00247076153755188,
  "Jeska/VaccinChatSentenceClassifierDutch_fromBERTje2_DAdialog": 0.002445697784423828,
  "Jeska/VaccinChatSentenceClassifierDutch_fromBERTje2_DAdialog02": 0.002445697784423828,
  "olastor/mcn-en-smm4h": 0.0024448037147521973,
  "mrm8488/bert-mini-finetuned-age_news-classification": 0.0024347305297851562,
  "jakelever/coronabert": 0.0024328231811523438,
  "milyiyo/multi-minilm-finetuned-amazon-review": 0.0024265050888061523,
  "tals/albert-base-vitaminc-fever": 0.00241243839263916,
  "aychang/roberta-base-imdb": 0.002409219741821289,
  "choondrise/emolve": 0.002401590347290039,
  "CAMeL-Lab/bert-base-arabic-camelbert-mix-did-nadi": 0.0024013519287109375,
  "boychaboy/MNLI_albert-base-v2": 0.002368532121181488,
  "marcolatella/emotion_trained": 0.0023620352149009705,
  "pietrotrope/emotion_final": 0.0023620352149009705,
  "Anamika/autonlp-Feedback1-479512837": 0.002341032028198242,
  "emrecan/distilbert-base-turkish-cased-allnli_tr": 0.0023393630981445312,
  "veronica320/MPTE_disjoint_adjs_MPE_roberta_200": 0.0023246407508850098,
  "DongHyoungLee/distilbert-base-uncased-finetuned-cola": 0.0023193955421447754,
  "bgoel4132/tweet-disaster-classifier": 0.0023193359375,
  "anel/autonlp-cml-412010597": 0.0023093223571777344,
  "Alireza1044/albert-base-v2-mnli": 0.0022947192192077637,
  "Jorgeutd/sagemaker-roberta-base-emotion": 0.002291560173034668,
  "textattack/roberta-base-MNLI": 0.002284705638885498,
  "mohsenfayyaz/bert-base-uncased-offenseval2019": 0.002272486686706543,
  "persiannlp/wikibert-base-parsinlu-entailment": 0.0022644996643066406,
  "Amalq/distilbert-base-uncased-finetuned-cola": 0.002247631549835205,
  "medA/autonlp-FR_another_test-565016091": 0.0022298991680145264,
  "Osiris/neutral_non_neutral_classifier": 0.002227783203125,
  "Luyu/bert-base-mdoc-hdct": 0.002221822738647461,
  "mamlong34/MiniLM-L6-snli_mnli_fever_anli_R1_R2_R3-nli": 0.002208143472671509,
  "harish/EN-AStitchTask1A-BERTBaseUncased-FalseTrue-0-0-BEST": 0.0022029876708984375,
  "nbroad/ESG-BERT": 0.002201080322265625,
  "milyiyo/distilbert-base-uncased-finetuned-amazon-review": 0.002196192741394043,
  "Jeska/autonlp-vaccinfaq-22144706": 0.0021958351135253906,
  "Hate-speech-CNERG/deoffxlmr-mono-tamil": 0.002185225486755371,
  "textattack/albert-base-v2-STS-B": 0.002184629440307617,
  "cointegrated/rubert-tiny-toxicity": 0.002179384231567383,
  "TehranNLP-org/roberta-base-mnli-2e-5-42": 0.0021708011627197266,
  "MelissaTESSA/distilbert-base-uncased-finetuned-cola": 0.0021416544914245605,
  "owen99630/catexp2": 0.0021342039108276367,
  "tbochens/test-train": 0.0021309852600097656,
  "pierreant-p/autonlp-jcvd-or-linkedin-3471039": 0.002123326063156128,
  "ehddnr301/bert-base-ehddnr-ynat": 0.00212252140045166,
  "aditeyabaral/finetuned-iitp_pdt_review-distilbert-hinglish-small": 0.0021142959594726562,
  "Hormigo/roberta-base-bne-finetuned-amazon_reviews_multi": 0.002111077308654785,
  "tals/albert-base-vitaminc_flagging": 0.0020911693572998047,
  "arianpasquali/twitter-xlm-roberta-base-sentiment-finetunned": 0.0020885467529296875,
  "mollypak/roberta-base": 0.002086639404296875,
  "aditeyabaral/finetuned-sail2017-indic-bert": 0.0020841658115386963,
  "NYTK/sentiment-hts5-xlm-roberta-hungarian": 0.0020791292190551758,
  "mrm8488/distilroberta-finetuned-banking77": 0.0020716190338134766,
  "Jeska/VaccinChatSentenceClassifierDutch_fromBERTje2_DAdialogQonly09": 0.0020487308502197266,
  "hcjang1987/distilbert-base-uncased-finetuned-cola": 0.0020487308502197266,
  "DoyyingFace/bert-tweets-semeval-clean": 0.0020456910133361816,
  "tals/albert-base-vitaminc_wnei-fever": 0.0020407438278198242,
  "DoyyingFace/bert-tweets-semeval-unclean": 0.002033233642578125,
  "jpabbuehl/distilbert-base-uncased-finetuned-cola": 0.0020331889390945435,
  "textattack/albert-base-v2-snli": 0.0020308494567871094,
  "mrm8488/camembert-base-finetuned-movie-review-sentiment-analysis": 0.002028226852416992,
  "korca/textfooler-roberta-base-mrpc": 0.002023935317993164,
  "textattack/albert-base-v2-QQP": 0.002010822296142578,
  "aditeyabaral/finetuned-iitp_pdt_review-indic-bert": 0.0020075440406799316,
  "Jeska/VaccinChatSentenceClassifierDutch_fromBERTje2": 0.00200653076171875,
  "Jungwoo/distilbert-base-uncased-finetuned-cola": 0.0019928961992263794,
  "fabriceyhc/bert-base-uncased-amazon_polarity": 0.0019693374633789062,
  "Narrativa/distilroberta-finetuned-stereotype-detection": 0.0019683837890625,
  "oseibrefo/distilbert-base-uncased-finetuned-cola": 0.0019653737545013428,
  "kapilchauhan/distilbert-base-uncased-finetuned-cola": 0.0019370019435882568,
  "oferweintraub/bert-base-finance-sentiment-noisy-search": 0.0019260644912719727,
  "pablouribe/bertstem-copus-overfitted": 0.001921147108078003,
  "l3cube-pune/hate-multi-roberta-hasoc-hindi": 0.0019185543060302734,
  "vionwinnie/albert-goodnotes-reddit": 0.001918196678161621,
  "Cameron/BERT-SBIC-targetcategory": 0.0019173622131347656,
  "addy88/programming-lang-identifier": 0.0019156336784362793,
  "huggingface/CodeBERTa-language-id": 0.0019156336784362793,
  "sahri/indonesiasentiment": 0.0019083023071289062,
  "w11wo/indonesian-roberta-base-sentiment-classifier": 0.0019083023071289062,
  "aditeyabaral/finetuned-iitpmovie-additionalpretrained-bert-base-cased": 0.0018770396709442139,
  "Tejas3/distillbert_base_uncased_80": 0.0018754005432128906,
  "zeus0007/test": 0.0018683671951293945,
  "textattack/albert-base-v2-CoLA": 0.001863718032836914,
  "mervenoyan/PubMedBERT-QNLI": 0.0018553733825683594,
  "Aimendo/autonlp-triage-35248482": 0.0018500089645385742,
  "amirhossein1376/pft-clf-finetuned": 0.0018498897552490234,
  "annafavaro/distilbert-base-uncased-finetuned-cola": 0.0018470287322998047,
  "deeq/dbert-sentiment": 0.0018367767333984375,
  "Vaibhavbrkn/grammer_classiffication": 0.0018335580825805664,
  "moshew/distilbert-base-uncased-finetuned-clinc": 0.0018322467803955078,
  "paintingpeter/distilbert-base-uncased-finetuned-clinc": 0.0018322467803955078,
  "widyanto/indobert-base-uncased-qa-evaluator": 0.0018298625946044922,
  "Maunish/kgrouping-roberta-large": 0.001827836036682129,
  "Lumos/yahoo2": 0.0018188953399658203,
  "DaNLP/da-bert-emotion-classification": 0.001814723014831543,
  "anelnurkayeva/autonlp-covid-432211280": 0.0018128659576177597,
  "symanto/xlm-roberta-base-snli-mnli-anli-xnli": 0.001804649829864502,
  "Eldar/bert-fine-tune-cola": 0.001801133155822754,
  "aditeyabaral/finetuned-iitp_pdt_review-additionalpretrained-indic-bert": 0.0017887353897094727,
  "staceythompson/autonlp-myclassification-fortext-16332728": 0.0017830729484558105,
  "Shuvam/autonlp-college_classification-164469": 0.0017666816711425781,
  "aXhyra/demo_irony_1234567": 0.0017659664154052734,
  "aXhyra/demo_irony_31415": 0.0017659664154052734,
  "aXhyra/demo_irony_42": 0.0017659664154052734,
  "aXhyra/presentation_emotion_1234567": 0.0017654895782470703,
  "celential/erc": 0.0017635226249694824,
  "sismetanin/rubert_conversational-ru-sentiment-sentirueval2016": 0.0017576813697814941,
  "aditeyabaral/finetuned-sail2017-roberta-base": 0.0017558485269546509,
  "TehranNLP-org/bert-base-uncased-avg-mnli-2e-5-63": 0.0017516613006591797,
  "digit82/dialog-sbert-base": 0.0017345249652862549,
  "celtics1863/env-bert-cls-chinese": 0.00173187255859375,
  "hugo/secret-project-ms-2": 0.0017316341400146484,
  "csalamea/roberta-base-bne-finetuned-amazon_reviews_multi": 0.0017310380935668945,
  "gchhablani/bert-base-cased-finetuned-cola": 0.001726388931274414,
  "m3hrdadfi/albert-fa-base-v2-sentiment-deepsentipers-binary": 0.0017242431640625,
  "anirudh21/albert-large-v2-finetuned-qqp": 0.0017223358154296875,
  "joelito/bert-base-uncased-sem_eval_2010_task_8": 0.0017197132110595703,
  "Cameron/BERT-mdgender-wizard": 0.0017189383506774902,
  "Jeska/VaccinChatSentenceClassifierDutch_fromBERTje": 0.001713395118713379,
  "textattack/albert-base-v2-ag-news": 0.0017015933990478516,
  "boychaboy/SNLI_roberta-large": 0.0016936063766479492,
  "edwardgowsmith/bert-base-cased-best": 0.0016935057938098907,
  "Kumicho/distilbert-base-uncased-finetuned-cola": 0.0016896724700927734,
  "finiteautomata/bert-contextualized-hate-speech-es": 0.0016856193542480469,
  "chinhon/fake_tweet_detect": 0.0016847103834152222,
  "sismetanin/rubert-ru-sentiment-sentirueval2016": 0.0016841292381286621,
  "aditeyabaral/finetuned-iitp_pdt_review-bert-hinglish-small": 0.0016803741455078125,
  "jx88/xlm-roberta-base-finetuned-marc-en-j-run": 0.0016741752624511719,
  "m3hrdadfi/albert-fa-base-v2-sentiment-deepsentipers-multi": 0.0016654133796691895,
  "prajjwal1/albert-base-v2-mnli": 0.0016648173332214355,
  "notentered/roberta-base-finetuned-cola": 0.0016603171825408936,
  "gmihaila/distilbert-base-uncased": 0.0016584396362304688,
  "beomi/distilbert-base-uncased-finetuned-cola": 0.0016565322875976562,
  "marcolatella/emotion_trained_31415": 0.0016499757766723633,
  "SharanSMenon/22-languages-bert-base-cased": 0.0016466379165649414,
  "Monsia/camembert-fr-covid-tweet-sentiment-classification": 0.0016458481550216675,
  "cross-encoder/stsb-TinyBERT-L-4": 0.0016438961029052734,
  "oemga38/distilbert-base-uncased-finetuned-cola": 0.0016431808471679688,
  "CAMeL-Lab/bert-base-arabic-camelbert-msa-poetry": 0.0016250312328338623,
  "msavel-prnt/distilbert-base-uncased-finetuned-clinc": 0.0016176700592041016,
  "mrm8488/RuPERTa-base-finetuned-pawsx-es": 0.0016127824783325195,
  "ks15/distilbert-base-uncased-finetuned-cola": 0.001610875129699707,
  "coppercitylabs/uzbek-news-category-classifier": 0.0016083717346191406,
  "bertin-project/bertin-base-xnli-es": 0.0016078874468803406,
  "zgotter/bert-base-finetuned-ynat": 0.0016021728515625,
  "lewtun/minilm-finetuned-emotion": 0.0016011595726013184,
  "akdeniz27/bert-turkish-text-classification": 0.0016005337238311768,
  "philschmid/DistilBERT-Banking77": 0.001599133014678955,
  "CouchCat/ma_mlc_v7_distil": 0.0015964508056640625,
  "aXhyra/presentation_emotion_42": 0.0015919208526611328,
  "ghanashyamvtatti/roberta-fake-news": 0.001590728759765625,
  "CleveGreen/JobClassifier": 0.0015861988067626953,
  "manishiitg/distilbert-resume-parts-classify": 0.0015857219696044922,
  "tanay/xlm-fine-tuned": 0.0015829205513000488,
  "nepalprabin/xlm-roberta-base-finetuned-marc-en": 0.0015810728073120117,
  "VirenS13117/distilbert-base-uncased-finetuned-cola": 0.0015691965818405151,
  "kittinan/exercise-feedback-classification": 0.001567736268043518,
  "textattack/distilbert-base-uncased-ag-news": 0.0015659332275390625,
  "ncduy/bert-base-cased-finetuned-emotion": 0.0015642642974853516,
  "mmcquade11/reviews-sentiment-analysis": 0.0015616416931152344,
  "wietsedv/bert-base-dutch-cased-finetuned-sentiment": 0.0015568733215332031,
  "milyiyo/minilm-finetuned-emotion": 0.0015561580657958984,
  "ueb1/IceBERT-finetuned-grouped": 0.001555219292640686,
  "DaNLP/da-bert-tone-sentiment-polarity": 0.0015529394149780273,
  "simonmun/Ey_SentenceClassification": 0.001552581787109375,
  "madlag/bert-large-uncased-mnli": 0.0015479326248168945,
  "marcelcastrobr/sagemaker-distilbert-emotion-2": 0.001547098159790039,
  "Elluran/Hate_speech_detector": 0.0015439987182617188,
  "alexander-karpov/bert-eatable-classification-en-ru": 0.0015344619750976562,
  "bhadresh-savani/roberta-base-emotion": 0.0015239715576171875,
  "anirudh21/albert-large-v2-finetuned-wnli": 0.0015174448490142822,
  "unicamp-dl/mMiniLM-L6-v2-en-msmarco": 0.0015115737915039062,
  "vesteinn/XLMR-ENIS-finetuned-cola": 0.0015102624893188477,
  "korca/bae-roberta-base-boolq": 0.0015090405941009521,
  "M47Labs/italian_news_classification_headlines": 0.0015059113502502441,
  "wilsontam/bert-base-uncased-dstc10-knowledge-cluster-classifier": 0.0015027523040771484,
  "Alireza1044/albert-base-v2-qqp": 0.0015020370483398438,
  "researchaccount/sa_sub3": 0.0014997422695159912,
  "researchaccount/sa_sub4": 0.0014997422695159912,
  "toanparadox/test_nlp": 0.001490861177444458,
  "tiesan/distilbert-base-uncased-finetuned-emotion": 0.0014903545379638672,
  "spencerh/centerpartisan": 0.0014889538288116455,
  "spencerh/leftcenterpartisan": 0.0014889538288116455,
  "spencerh/rightcenterpartisan": 0.0014889538288116455,
  "Alireza1044/albert-base-v2-stsb": 0.0014835596084594727,
  "aXhyra/emotion_trained_42": 0.001475691795349121,
  "csatapathy/interview-ratings-bert": 0.0014742016792297363,
  "Alstractor/distilbert-base-uncased-finetuned-cola": 0.0014603137969970703,
  "pparasurama/raceBERT-ethnicity": 0.001459747552871704,
  "mateocolina/xlm-roberta-base-finetuned-marc-en": 0.0014594793319702148,
  "Yuri/xlm-roberta-base-finetuned-marc": 0.0014535188674926758,
  "simonmun/Lo_SentenceClassification": 0.0014505982398986816,
  "123abhiALFLKFO/distilbert-base-uncased-finetuned-cola": 0.0014484226703643799,
  "korca/bae-roberta-base-mrpc-5": 0.0014455914497375488,
  "aXhyra/irony_trained_42": 0.0014388561248779297,
  "textattack/roberta-base-ag-news": 0.0014380216598510742,
  "adamlin/ml999_wood": 0.001434326171875,
  "ttajun/bert_nm100k_posneg01": 0.0014330148696899414,
  "mazancourt/politics-sentence-classifier": 0.001418471336364746,
  "Fiona99/distilbert-base-uncased-finetuned-cola": 0.0014171451330184937,
  "Monsia/camembert-fr-covid-tweet-classification": 0.001414179801940918,
  "2umm3r/distilbert-base-uncased-finetuned-cola": 0.0014137625694274902,
  "phailyoor/distilbert-base-uncased-finetuned-yahd-twval": 0.0013988018035888672,
  "aditeyabaral/finetuned-sail2017-bert-base-cased": 0.001397848129272461,
  "sismetanin/rubert-ru-sentiment-rutweetcorp": 0.001397848129272461,
  "Herais/pred_genre": 0.0013896822929382324,
  "m3hrdadfi/bert-fa-base-uncased-farstail": 0.0013890266418457031,
  "textattack/distilbert-base-cased-QQP": 0.0013887882232666016,
  "eliza-dukim/bert-base-finetuned-ynat": 0.0013747215270996094,
  "Anamika/autonlp-fa-473312409": 0.001371622085571289,
  "oliverqq/scibert-uncased-topics": 0.0013665109872817993,
  "CAMeL-Lab/bert-base-arabic-camelbert-da-poetry": 0.001363903284072876,
  "harish/PT-UP-xlmR-FalseFalse-OneShot-0_BEST": 0.0013630688190460205,
  "fabriceyhc/bert-base-uncased-dbpedia_14": 0.001346588134765625,
  "johnpaulbin/cvai-bert-asag": 0.0013437867164611816,
  "boychaboy/SNLI_bert-base-uncased": 0.0013363957405090332,
  "classla/bcms-bertic-frenk-hate": 0.0013356208801269531,
  "Jodsa/camembert_clf": 0.0013349652290344238,
  "tkesonia/xlm-roberta-base-finetuned-marc-en": 0.0013347268104553223,
  "SetFit/distilbert-base-uncased__TREC-QC__all-train": 0.0013270974159240723,
  "cambridgeltl/trans-encoder-cross-simcse-roberta-base": 0.0013265609741210938,
  "boronbrown48/wangchanberta-sentiment-v2": 0.00131988525390625,
  "hadxu/distilbert-base-uncased-finetuned-clinc": 0.001316159963607788,
  "federicopascual/distilbert-base-uncased-finetuned-cola": 0.0013151168823242188,
  "MoritzLaurer/covid-policy-roberta-21": 0.00130462646484375,
  "chisadi/nice-distilbert-v2": 0.0013031959533691406,
  "tucan9389/distilbert-base-uncased-finetuned-cola": 0.0013025403022766113,
  "boychaboy/MNLI_bert-base-cased_4": 0.001300215721130371,
  "textattack/roberta-base-QNLI": 0.0012939274311065674,
  "ueb1/IceBERT-finetuned": 0.0012935400009155273,
  "bipin/malayalam-news-classifier": 0.0012841224670410156,
  "Jeska/VaccinChatSentenceClassifierDutch_fromBERTjeDIAL": 0.0012829303741455078,
  "aXhyra/presentation_sentiment_42": 0.0012818574905395508,
  "cross-encoder/ms-marco-MiniLM-L-2-v2": 0.0012807846069335938,
  "textattack/bert-base-uncased-snli": 0.0012748241424560547,
  "ninahrostozova/xlm-roberta-base-finetuned-marc": 0.0012744143605232239,
  "Guscode/DKbert-hatespeech-detection": 0.0012712478637695312,
  "michaelhsieh42/distilbert-base-uncased-finetuned-cola": 0.001270189881324768,
  "transformersbook/bert-base-uncased-finetuned-clinc": 0.0012691020965576172,
  "aristotletan/scim-distilroberta": 0.001268923282623291,
  "yoshitomo-matsubara/bert-base-uncased-cola_from_bert-large-uncased-cola": 0.0012668371200561523,
  "tals/albert-base-vitaminc-mnli": 0.0012646839022636414,
  "Hate-speech-CNERG/deoffxlmr-mono-kannada": 0.0012634247541427612,
  "sismetanin/xlm_roberta_base-ru-sentiment-krnd": 0.0012611746788024902,
  "flax-community/bert-swahili-news-classification": 0.0012591853737831116,
  "bhadresh-savani/distilbert-base-uncased-emotion": 0.0012590885162353516,
  "ajrae/bert-base-uncased-finetuned-mrpc": 0.0012461543083190918,
  "shivangi/CoLA_64_128_output": 0.0012439899146556854,
  "persiannlp/parsbert-base-parsinlu-entailment": 0.0012404918670654297,
  "usami/distilbert-base-uncased-finetuned-cola": 0.001238703727722168,
  "Monsia/autonlp-tweets-classification-23044997": 0.0012340545654296875,
  "j-hartmann/emotion-english-roberta-large": 0.0012223273515701294,
  "arianpasquali/distilbert-base-uncased-finetuned-clinc": 0.0012221336364746094,
  "TehranNLP-org/bert-base-uncased-avg-mnli": 0.0012177228927612305,
  "TehranNLP-org/roberta-base-qqp-2e-5-42": 0.001216888427734375,
  "moshew/BERT-small-finetuned-clinc": 0.001214444637298584,
  "persiannlp/mbert-base-parsinlu-entailment": 0.001213371753692627,
  "Vasanth/tamil-sentiment-distilbert": 0.0012104511260986328,
  "pparasurama/racBERT-race-pretrained": 0.0012104511260986328,
  "anirudh21/albert-base-v2-finetuned-rte": 0.0012093037366867065,
  "tobiaslee/roberta-large-qa-suffix-defteval-t6-st1": 0.001209259033203125,
  "RavenK/bert-base-uncased-sst2": 0.0012066066265106201,
  "dkhara/bert-news": 0.0012061595916748047,
  "cross-encoder/nli-distilroberta-base": 0.0012052059173583984,
  "boychaboy/MNLI_distilbert-base-cased": 0.001203298568725586,
  "jpabbuehl/sagemaker-distilbert-emotion": 0.001201540231704712,
  "l3cube-pune/hate-bert-hasoc-marathi": 0.0011980533599853516,
  "idrimadrid/autonlp-creator_classifications-4021083": 0.0011966228485107422,
  "erica/krm_sa2": 0.0011925697326660156,
  "erica/krm_sa3": 0.0011925697326660156,
  "snunlp/KR-FinBert-SC": 0.0011925697326660156,
  "09panesara/distilbert-base-uncased-finetuned-cola": 0.001191645860671997,
  "NTUYG/DeepSCC-RoBERTa": 0.001189112663269043,
  "howey/bert-base-uncased-qnli": 0.0011879205703735352,
  "philschmid/MiniLMv2-L6-H384-emotion": 0.0011861324310302734,
  "SkolkovoInstitute/roberta_toxicity_classifier_v1": 0.0011854171752929688,
  "CAMeL-Lab/bert-base-arabic-camelbert-mix-poetry": 0.001176595687866211,
  "ncduy/roberta-imdb-sentiment-analysis": 0.0011708736419677734,
  "riyadhctg/distilbert-base-uncased-finetuned-cola": 0.0011707842350006104,
  "gurkan08/bert-turkish-text-classification": 0.0011682510375976562,
  "cscottp27/distilbert-base-uncased-finetuned-emotion": 0.0011634230613708496,
  "abhishek/autonlp-bbc-news-classification-37229289": 0.0011625289916992188,
  "zwang199/autonlp-traffic_nlp_binary-537215209": 0.0011601448059082031,
  "XSY/albert-base-v2-fakenews-discriminator": 0.0011491775512695312,
  "TehranNLP-org/bert-base-cased-avg-mnli": 0.0011464357376098633,
  "textattack/bert-base-uncased-rotten-tomatoes": 0.0011436939239501953,
  "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment": 0.0011386275291442871,
  "aditeyabaral/finetuned-sail2017-xlm-roberta-base": 0.0011378824710845947,
  "lucianpopa/autonlp-SST2-551215591": 0.0011378228664398193,
  "Elron/bleurt-tiny-128": 0.0011350512504577637,
  "yoshitomo-matsubara/bert-base-uncased-qqp": 0.0011348724365234375,
  "ainize/klue-bert-base-re": 0.001131489872932434,
  "JP040/bert-german-sentiment-twitter": 0.0011281967163085938,
  "philschmid/DistilBERT-tweet-eval-emotion": 0.001127481460571289,
  "prajjwal1/albert-base-v1-mnli": 0.0011270344257354736,
  "pedropei/live-demo-question-intimacy": 0.0011266469955444336,
  "TehranNLP-org/bert-base-uncased-avg-cola-2e-5-42": 0.0011255741119384766,
  "amberoad/bert-multilingual-passage-reranking-msmarco": 0.0011239051818847656,
  "aditeyabaral/finetuned-sail2017-additionalpretrained-indic-bert": 0.0011230111122131348,
  "StevenLimcorn/indonesian-roberta-base-emotion-classifier": 0.0011185407638549805,
  "boychaboy/SNLI_distilbert-base-cased": 0.001118302345275879,
  "PubChimps/dlfBERT": 0.0011175870895385742,
  "asalics/distilbert-base-uncased-finetuned-emotion": 0.0011175870895385742,
  "pin/analytical": 0.0011175274848937988,
  "bierus/distilbert_bookreviews": 0.0011167526245117188,
  "MadhurJindalWorkMail/autonlp-Gibb-Detect-515314387": 0.0011081695556640625,
  "bob1966/distilbert-base-uncased-finetuned-cola": 0.0011074542999267578,
  "cointegrated/rubert-base-cased-nli-twoway": 0.0011063218116760254,
  "joeddav/distilbert-base-uncased-go-emotions-student": 0.0010995566844940186,
  "Theivaprakasham/bert-base-cased-twitter_sentiment": 0.0010991096496582031,
  "yoshitomo-matsubara/bert-base-uncased-mnli": 0.0010984539985656738,
  "Kieran/distilbert-base-uncased-finetuned-cola": 0.0010983943939208984,
  "uer/roberta-base-finetuned-chinanews-chinese": 0.0010981559753417969,
  "boychaboy/MNLI_bert-base-uncased": 0.0010967254638671875,
  "geckos/bert-base-uncased-finetuned-glue-cola": 0.0010963380336761475,
  "prithivida/parrot_fluency_on_BERT": 0.0010963380336761475,
  "textattack/bert-base-uncased-CoLA": 0.0010963380336761475,
  "l3cube-pune/hate-roberta-hasoc-hindi": 0.0010849833488464355,
  "kco4776/soongsil-bert-wellness": 0.0010805130004882812,
  "andi611/distilbert-base-uncased-ner-agnews": 0.0010752677917480469,
  "mdhugol/indonesia-bert-sentiment-classification": 0.0010737180709838867,
  "IMSyPP/hate_speech_it": 0.001072317361831665,
  "vinaydngowda/Robertabase_Ana4": 0.0010706186294555664,
  "DeadBeast/korscm-mBERT": 0.0010703802108764648,
  "moshew/BERT-small-distilled-clinc": 0.0010699629783630371,
  "bioformers/bioformer-cased-v1.0-mnli": 0.001069486141204834,
  "pooyaphoenix/distilbert-base-uncased-finetuned-cola": 0.0010690689086914062,
  "carlosaguayo/distilbert-base-uncased-finetuned-emotion": 0.0010677576065063477,
  "kangnichaluo/cb": 0.0010619163513183594,
  "mofawzy/arbert-goodreads": 0.0010592937469482422,
  "MoritzLaurer/policy-distilbert-7d": 0.0010585784912109375,
  "boychaboy/MNLI_distilbert-base-cased_2": 0.0010585784912109375,
  "deepset/gbert-large-sts": 0.001056671142578125,
  "transformersbook/distilbert-base-uncased-finetuned-clinc": 0.0010529309511184692,
  "chrommium/rubert-base-cased-sentence-finetuned-sent_in_news_sents": 0.0010510683059692383,
  "distilbert-base-uncased-finetuned-sst-2-english": 0.0010499954223632812,
  "lysandre/new-dummy-model": 0.0010499954223632812,
  "ikevin98/bert-base-uncased-sst2-distilled": 0.0010497570037841797,
  "assemblyai/distilbert-base-uncased-qqp": 0.0010480880737304688,
  "LilaBoualili/bert-pre-doc": 0.001047670841217041,
  "CAMeL-Lab/bert-base-arabic-camelbert-msa-did-madar-twitter5": 0.0010466575622558594,
  "Elron/bleurt-base-512": 0.0010466575622558594,
  "pierric/autonlp-my-own-imdb-sentiment-analysis-2131817": 0.0010459423065185547,
  "tr3cks/SentimentAnalysis_BETO": 0.0010457932949066162,
  "researchaccount/sa_sub1": 0.0010409355163574219,
  "echarlaix/bert-base-uncased-sst2-acc91.1-d37-hybrid": 0.0010395050048828125,
  "CAMeL-Lab/bert-base-arabic-camelbert-msa-did-nadi": 0.0010377168655395508,
  "CLTL/icf-domains": 0.0010366439819335938,
  "dpalominop/spanish-bert-apoyo": 0.0010349750518798828,
  "moshew/tiny-bert-sst2-distilled": 0.001033782958984375,
  "aXhyra/presentation_irony_31415": 0.0010311007499694824,
  "M47Labs/it_iptc": 0.0010310113430023193,
  "fznmhmmd/distilbert-base-uncased-finetuned-cola": 0.0010297298431396484,
  "Mathking/bert-base-german-cased-gnad10": 0.0010223984718322754,
  "w11wo/javanese-bert-small-imdb-classifier": 0.0010204911231994629,
  "adamlin/filter": 0.0010197758674621582,
  "aditeyabaral/finetuned-iitp_pdt_review-distilbert-hinglish-big": 0.001018524169921875,
  "appleternity/scibert-uncased-finetuned-coda19": 0.0010168254375457764,
  "tcaputi/guns-relevant": 0.0010137557983398438,
  "tcaputi/guns-relevant-b300": 0.0010137557983398438,
  "EMBEDDIA/sloberta-tweetsentiment": 0.0010131970047950745,
  "ardauzunoglu/c_ovk": 0.0010113716125488281,
  "emrecan/bert-base-multilingual-cased-snli_tr": 0.0010109487920999527,
  "akahana/indonesia-sentiment-roberta": 0.001007080078125,
  "bergum/xtremedistil-l6-h384-go-emotion": 0.0010042190551757812,
  "harithapliyal/distilbert-base-uncased-finetuned-cola": 0.0010016560554504395,
  "tals/albert-base-mnli": 0.0010003969073295593,
  "rexxar96/autonlp-roberta-large-finetuned-467612250": 0.0009968280792236328,
  "Alireza1044/albert-base-v2-qnli": 0.0009932518005371094,
  "sismetanin/rubert-ru-sentiment-krnd": 0.0009930729866027832,
  "federicopascual/finetune-sentiment-analysis-model-3000-samples": 0.0009888410568237305,
  "unicamp-dl/mMiniLM-L6-v2-mmarco-v1": 0.0009876489639282227,
  "khanhpd2/distilBERT-emotionv2": 0.0009824633598327637,
  "khanhpd2/distilbert-emotion": 0.0009824633598327637,
  "madhurjindal/autonlp-Gibberish-Detector-492513457": 0.0009818077087402344,
  "marcolatella/emotion_trained_1234567": 0.0009804964065551758,
  "DoyyingFace/bert-asian-hate-tweets-self-clean": 0.000980377197265625,
  "LilaBoualili/bert-sim-pair": 0.0009795427322387695,
  "M-FAC/bert-mini-finetuned-mrpc": 0.000978231430053711,
  "o2poi/sst2-eda-bert-uncased": 0.0009779930114746094,
  "uer/roberta-base-finetuned-dianping-chinese": 0.0009770989418029785,
  "AnonARR/qqp-bert": 0.0009756088256835938,
  "zyl1024/bert-base-cased-finetuned-qqp": 0.0009756088256835938,
  "DTAI-KULeuven/mbert-corona-tweets-belgium-curfew-support": 0.0009732246398925781,
  "gagandeepkundi/latam-question-quality": 0.0009731054306030273,
  "Lumos/yahoo1": 0.0009670257568359375,
  "fabriceyhc/bert-base-uncased-yahoo_answers_topics": 0.0009670257568359375,
  "ismaelardo/BETO_4d": 0.0009660720825195312,
  "julien-c/distilbert-sagemaker-1609802168": 0.0009655952453613281,
  "aychang/bert-base-cased-trec-coarse": 0.0009627342224121094,
  "textattack/distilbert-base-uncased-QQP": 0.0009605884552001953,
  "nihaldsouza1/yelp-rating-classification": 0.0009558200836181641,
  "papluca/xlm-roberta-base-language-detection": 0.0009522438049316406,
  "bespin-global/klue-roberta-small-3i4k-intent-classification": 0.0009508132934570312,
  "emrecan/bert-base-multilingual-cased-allnli_tr": 0.0009502768516540527,
  "aXhyra/emotion_trained_31415": 0.0009480714797973633,
  "M-FAC/bert-mini-finetuned-sst2": 0.000947117805480957,
  "CAMeL-Lab/bert-base-arabic-camelbert-ca-poetry": 0.0009456872940063477,
  "MhF/distilbert-base-uncased-finetuned-emotion": 0.0009456872940063477,
  "savasy/bert-base-turkish-sentiment-cased": 0.0009436607360839844,
  "EthanChen0418/intent_cls": 0.000941932201385498,
  "elozano/bert-base-cased-news-category": 0.0009398460388183594,
  "abdelkader/distilbert-base-uncased-finetuned-clinc": 0.0009383559226989746,
  "aristotletan/roberta-base-finetuned-sst2": 0.0009378194808959961,
  "navsad/navid_test_bert": 0.0009360015392303467,
  "aditeyabaral/finetuned-sail2017-additionalpretrained-roberta-base": 0.0009355545043945312,
  "aditeyabaral/finetuned-iitp_pdt_review-bert-hinglish-big": 0.0009342730045318604,
  "mofawzy/bert-ajgt": 0.0009341239929199219,
  "moshew/MiniLM-L3-sst2-distilled": 0.000933423638343811,
  "textattack/roberta-base-STS-B": 0.0009334087371826172,
  "anirudh21/bert-base-uncased-finetuned-qnli": 0.0009309053421020508,
  "gchhablani/bert-base-cased-finetuned-mnli": 0.0009306669235229492,
  "kdo6301/bert-base-uncased-finetuned-cola-2": 0.0009303689002990723,
  "mohsenfayyaz/toxicity-classifier": 0.0009293556213378906,
  "nlptown/bert-base-multilingual-uncased-sentiment": 0.0009256601333618164,
  "tomato/sentiment_analysis": 0.0009256601333618164,
  "SetFit/distilbert-base-uncased__subj__train-8-6": 0.0009225904941558838,
  "flax-community/roberta-swahili-news-classification": 0.0009225606918334961,
  "Proggleb/roberta-base-bne-finetuned-amazon_reviews_multi": 0.0009194910526275635,
  "voxmenthe/distilbert-base-uncased-finetuned-emotion": 0.000912785530090332,
  "transformersbook/distilbert-base-uncased-distilled-clinc": 0.0009095668792724609,
  "yoshitomo-matsubara/bert-base-uncased-mnli_from_bert-large-uncased-mnli": 0.0009089410305023193,
  "lucianpopa/autonlp-SST1-529214890": 0.0009064674377441406,
  "textattack/bert-base-uncased-yelp-polarity": 0.0009064674377441406,
  "uer/roberta-base-finetuned-ifeng-chinese": 0.0009059906005859375,
  "akilesh96/autonlp-mrcooper_text_classification-529614927": 0.0009056329727172852,
  "emrecan/bert-base-turkish-cased-snli_tr": 0.0009050965309143066,
  "prajjwal1/bert-medium-mnli": 0.0009049177169799805,
  "Blaine-Mason/hackMIT-finetuned-sst2": 0.0009038448333740234,
  "lewtun/roberta-base-bne-finetuned-amazon_reviews_multi": 0.0009014010429382324,
  "bhadresh-savani/bert-base-go-emotion": 0.0009012222290039062,
  "aXhyra/presentation_hate_31415": 0.0009005069732666016,
  "jorgemariocalvo/roberta-base-bne-finetuned-amazon_reviews_multi": 0.0009002685546875,
  "cardiffnlp/twitter-xlm-roberta-base-sentiment": 0.0008984208106994629,
  "mrm8488/codebert2codebert-finetuned-code-defect-detection": 0.0008981823921203613,
  "boychaboy/MNLI_bert-base-cased": 0.0008957386016845703,
  "boychaboy/MNLI_bert-base-cased_2": 0.0008957386016845703,
  "auychai/distilbert-base-uncased-finetuned-emotion": 0.0008951425552368164,
  "GD/cq-bert-model-repo": 0.0008948445320129395,
  "pinecone/bert-medqp-cross-encoder": 0.0008932352066040039,
  "aXhyra/sentiment_trained_1234567": 0.0008920431137084961,
  "oumeima/finetuned-bert-mrpc": 0.0008902102708816528,
  "mrm8488/bert-tiny-finetuned-yahoo_answers_topics": 0.000883936882019043,
  "TehranNLP/albert-base-v2-mnli": 0.0008838921785354614,
  "aditeyabaral/finetuned-sail2017-distilbert-base-cased": 0.0008801817893981934,
  "cross-encoder/nli-MiniLM2-L6-H768": 0.0008790716528892517,
  "HackMIT/double-agent": 0.0008785724639892578,
  "jgonik/nlp-puzzle": 0.0008785724639892578,
  "w11wo/indonesian-roberta-base-indonli": 0.0008782148361206055,
  "avneet/distilbert-base-uncased-finetuned-sst2": 0.0008687973022460938,
  "zwang199/autonlp-traffic-nlp-451311592": 0.0008656829595565796,
  "finiteautomata/beto-emotion-analysis": 0.000864565372467041,
  "blackbird/bert-base-uncased-MNLI-v1": 0.0008612275123596191,
  "seongju/kor-3i4k-bert-base-cased": 0.0008567571640014648,
  "boychaboy/MNLI_bert-large-cased": 0.0008542537689208984,
  "shahrukhx01/roberta-base-boolq": 0.0008534491062164307,
  "o2poi/sst2-eda-bert": 0.0008516311645507812,
  "MisbaHF/distilbert-base-uncased-finetuned-cola": 0.0008513927459716797,
  "Prompsit/paraphrase-bert-en": 0.0008511543273925781,
  "Lumos/ag_news1": 0.0008476972579956055,
  "savasy/bert-turkish-text-classification": 0.000845789909362793,
  "Cameron/BERT-rtgender-opgender-annotations": 0.0008422136306762695,
  "M47Labs/spanish_news_classification_headlines": 0.0008416175842285156,
  "juliensimon/reviews-sagemaker-demo": 0.0008411407470703125,
  "phailyoor/distilbert-base-uncased-finetuned-yahd-twval-hptune": 0.0008404254913330078,
  "korca/bae-roberta-base-sst2": 0.0008323192596435547,
  "joniponi/bert-finetuned-sem_eval-english": 0.0008320808410644531,
  "fadhilarkan/distilbert-base-uncased-finetuned-cola-4": 0.0008312463760375977,
  "pablouribe/bertstem-copus": 0.0008307695388793945,
  "cross-encoder/ms-marco-TinyBERT-L-6": 0.0008296966552734375,
  "gchhablani/bert-base-cased-finetuned-rte": 0.0008291900157928467,
  "textattack/distilbert-base-uncased-imdb": 0.0008274316787719727,
  "assemblyai/distilbert-base-uncased-sst2": 0.0008239969611167908,
  "textattack/distilbert-base-uncased-RTE": 0.000822901725769043,
  "howey/bert-base-uncased-sst2": 0.0008227825164794922,
  "M-FAC/bert-mini-finetuned-mnli": 0.0008144676685333252,
  "bowipawan/bert-sentimental": 0.0008134841918945312,
  "CleveGreen/FieldClassifier_v2": 0.0008118152618408203,
  "zhangle/distilbert-base-uncased-finetuned-cola": 0.000811450183391571,
  "lupinlevorace/tiny-bert-sst2-distilled": 0.0008109211921691895,
  "NYTK/sentiment-hts5-hubert-hungarian": 0.0008103251457214355,
  "mmcquade11/reviews-sentiment-analysis-two": 0.0008094310760498047,
  "aXhyra/presentation_emotion_31415": 0.0008070468902587891,
  "MarioPenguin/finetuned-model": 0.0008044242858886719,
  "aditeyabaral/finetuned-iitp_pdt_review-roberta-hinglish-small": 0.0008041858673095703,
  "Worldman/distilbert-base-uncased-finetuned-emotion": 0.0008034706115722656,
  "LilaBoualili/bert-pre-pair": 0.0008015632629394531,
  "SetFit/distilbert-base-uncased__sst2__all-train": 0.0007987618446350098,
  "trnt/twitter_emotions": 0.0007966756820678711,
  "adelgasmi/autonlp-kpmg_nlp-18833547": 0.0007964670658111572,
  "JIWON/bert-base-finetuned-nli": 0.0007961094379425049,
  "IMSyPP/hate_speech_nl": 0.0007958412170410156,
  "JuliusAlphonso/dear-jarvis-monolith-xed-en": 0.0007956027984619141,
  "chitra/distilbert-negation": 0.0007920265197753906,
  "huggingface/distilbert-base-uncased-finetuned-mnli": 0.0007920265197753906,
  "arjunth2001/priv_ftc": 0.0007914304733276367,
  "amansolanki/autonlp-Tweet-Sentiment-Extraction-20114061": 0.0007911920547485352,
  "abhishek/autonlp-bbc-roberta-37249301": 0.0007900595664978027,
  "roberta-base-openai-detector": 0.0007897913455963135,
  "cointegrated/rubert-base-cased-dp-paraphrase-detection": 0.0007864832878112793,
  "mrm8488/distilroberta-finetuned-rotten_tomatoes-sentiment-analysis": 0.0007860660552978516,
  "howey/roberta-large-qqp": 0.0007843971252441406,
  "robkayinto/distilbert-base-uncased-finetuned-emotion": 0.0007824897766113281,
  "adamlin/ml999_matal_bed": 0.0007808208465576172,
  "echarlaix/distilbert-base-uncased-sst2-magnitude-pruning-test": 0.0007784366607666016,
  "HooshvareLab/bert-fa-base-uncased-clf-persiannews": 0.0007762033492326736,
  "adamlin/ml999_power_punching_and_shearing_machinery": 0.0007755756378173828,
  "juliensimon/autonlp-song-lyrics-18753417": 0.0007753372192382812,
  "sana-ngu/Hat5-Roberta": 0.0007716119289398193,
  "StevenLimcorn/indo-roberta-indonli": 0.0007665157318115234,
  "seongju/klue-tc-bert-base-multilingual-cased": 0.0007658004760742188,
  "edbeeching/test-trainer-to-hub": 0.0007653236389160156,
  "bvanaken/clinical-assertion-negation-bert": 0.0007652044296264648,
  "anirudh21/distilbert-base-uncased-finetuned-sst2": 0.0007638931274414062,
  "TehranNLP-org/bert-base-cased-avg-cola": 0.0007628202438354492,
  "mrm8488/bsc-roberta-base-spanish-diagnostics": 0.0007625818252563477,
  "CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment": 0.0007617473602294922,
  "vesteinn/XLMR-ENIS-finetuned-stsb": 0.0007615089416503906,
  "Alireza1044/albert-base-v2-mrpc": 0.0007609128952026367,
  "aditeyabaral/finetuned-iitp_pdt_review-roberta-hinglish-big": 0.0007596015930175781,
  "harish/PT-XLM_R-FalseTrue-0_2_BEST": 0.0007581710815429688,
  "vesteinn/IceBERT-finetuned-iec-sentence-bs16": 0.0007561445236206055,
  "ghomasHudson/style_change_detection": 0.0007557868957519531,
  "vslaykovsky/roberta-news-duplicates": 0.0007556676864624023,
  "bhadresh-savani/bert-base-uncased-emotion": 0.0007555708289146423,
  "Crives/distilbert-base-uncased-finetuned-emotion": 0.0007554441690444946,
  "Parsa/BBB_prediction_classification_IUPAC": 0.0007537603378295898,
  "beomi/beep-KR-Medium-hate": 0.0007524043321609497,
  "nickmuchi/distilroberta-finetuned-finclass": 0.0007510185241699219,
  "textattack/bert-base-uncased-ag-news": 0.0007510185241699219,
  "reatiny/distilbert-base-uncased-finetuned-emotion": 0.0007475018501281738,
  "juliensimon/reviews-sentiment-analysis": 0.0007474422454833984,
  "mflorinsky/distilbert-base-uncased-finetuned-cola": 0.0007464289665222168,
  "Theivaprakasham/sentence-transformers-paraphrase-MiniLM-L6-v2-twitter_sentiment": 0.0007455646991729736,
  "sangrimlee/bert-base-multilingual-cased-nsmc": 0.0007446408271789551,
  "ZZDDBBCC/distilbert-base-uncased-finetuned-cola": 0.0007444620132446289,
  "hackertec/roberta-base-bne-finetuned-amazon_reviews_multi": 0.0007424354553222656,
  "cardiffnlp/twitter-roberta-base-emotion": 0.0007414817810058594,
  "rodrigogelacio/autonlp-department-classification-534915130": 0.0007390379905700684,
  "kaisugi/scibert-csabstruct": 0.0007370114326477051,
  "textattack/roberta-base-SST-2": 0.0007340908050537109,
  "Qinghui/autonlp-fake-covid-news-36769078": 0.0007333755493164062,
  "NikolajMunch/danish-emotion-classification": 0.0007297992706298828,
  "o2poi/sst2-eda-roberta": 0.0007290840148925781,
  "BearThreat/distilbert-base-uncased-finetuned-cola": 0.0007264614105224609,
  "poom-sci/WangchanBERTa-finetuned-sentiment": 0.0007263422012329102,
  "EhsanAghazadeh/xlm-roberta-base-lcc-fa-2e-5-42": 0.0007212162017822266,
  "marcolatella/hate_trained_1234567": 0.0007202625274658203,
  "boychaboy/SNLI_bert-large-cased": 0.0007189810276031494,
  "yoshitomo-matsubara/bert-base-uncased-cola": 0.0007188320159912109,
  "rohanrajpal/bert-base-multilingual-codemixed-cased-sentiment": 0.0007187128067016602,
  "meghanabhange/Hinglish-Bert-Class": 0.0007179975509643555,
  "verloop/Hinglish-Bert-Class": 0.0007179975509643555,
  "kdo6301/bert-base-uncased-finetuned-cola": 0.0007178187370300293,
  "The-Data-Hound/bacteria_lamp_network": 0.0007174015045166016,
  "airKlizz/xlm-roberta-base-germeval21-toxic-with-data-augmentation": 0.0007172822952270508,
  "appleternity/bert-base-uncased-finetuned-coda19": 0.0007147789001464844,
  "SetFit/distilbert-base-uncased__subj__train-8-1": 0.0007143020629882812,
  "aXhyra/emotion_trained_1234567": 0.0007139444351196289,
  "BritishLibraryLabs/bl-books-genre": 0.0007095932960510254,
  "JuliusAlphonso/dear-jarvis-v5": 0.00070953369140625,
  "deeq/dbert-eth2": 0.00070953369140625,
  "lvargas/distilbert-base-uncased-finetuned-emotion2": 0.0007092952728271484,
  "kamivao/autonlp-cola_gram-208681": 0.0007084012031555176,
  "adamlin/ml999_grinding_wheel": 0.0007083415985107422,
  "yoshitomo-matsubara/bert-base-uncased-qnli_from_bert-large-uncased-qnli": 0.0007078647613525391,
  "boychaboy/SNLI_roberta-base": 0.0007072091102600098,
  "blizrys/distilbert-base-uncased-finetuned-mnli": 0.0007067322731018066,
  "aloxatel/bert-base-mnli": 0.0007065832614898682,
  "Tahsin-Mayeesha/bangla-fake-news-mbert": 0.0007061958312988281,
  "banjtheman/distilbert-base-uncased-helpful-amazon": 0.0007052421569824219,
  "rohanrajpal/bert-base-en-hi-codemix-cased": 0.0007047653198242188,
  "ProsusAI/finbert": 0.0007033348083496094,
  "srosy/distilbert-base-uncased-finetuned-emotion": 0.0007027387619018555,
  "leeyujin/distilbert-base-uncased-finetuned-cola": 0.0007027238607406616,
  "VictorSanh/roberta-base-finetuned-yelp-polarity": 0.0006978511810302734,
  "pranav1015/distilbert-base-uncased-finetuned-cola": 0.0006943643093109131,
  "transformersbook/distilbert-base-uncased-finetuned-emotion": 0.0006936192512512207,
  "korca/textfooler-roberta-base-rte-5": 0.000691533088684082,
  "JuliusAlphonso/distilbert-plutchik": 0.0006906986236572266,
  "Azaghast/DistilBERT-SCP-Class-Classification": 0.0006896629929542542,
  "aXhyra/presentation_sentiment_1234567": 0.0006850957870483398,
  "aXhyra/presentation_sentiment_31415": 0.0006850957870483398,
  "mrm8488/distilroberta-base-finetuned-suicide-depression": 0.0006846189498901367,
  "nateraw/bert-base-uncased-emotion": 0.0006822049617767334,
  "deepset/bert-base-german-cased-sentiment-Germeval17": 0.0006818771362304688,
  "researchaccount/sa_sub5": 0.0006815195083618164,
  "aditeyabaral/finetuned-sail2017-additionalpretrained-bert-base-cased": 0.0006809532642364502,
  "prajjwal1/bert-small-mnli": 0.0006783604621887207,
  "yoshitomo-matsubara/bert-large-uncased-sst2": 0.0006761550903320312,
  "Jeska/VaccinChatSentenceClassifierDutch": 0.0006725788116455078,
  "philschmid/MiniLMv2-L12-H384-emotion": 0.000672459602355957,
  "cardiffnlp/twitter-roberta-base-stance-atheism": 0.0006694197654724121,
  "XSY/albert-base-v2-scarcasm-discriminator": 0.0006690025329589844,
  "kornosk/bert-election2020-twitter-stance-biden": 0.0006670951843261719,
  "elozano/tweet_sentiment_eval": 0.0006657838821411133,
  "textattack/distilbert-base-uncased-CoLA": 0.0006656497716903687,
  "wangyuwei/bert_cn_finetuning": 0.0006651878356933594,
  "mnaylor/base-bert-finetuned-mtsamples": 0.0006647109985351562,
  "gchhablani/bert-base-cased-finetuned-stsb": 0.0006625056266784668,
  "akahana/indonesia-emotion-roberta": 0.0006616711616516113,
  "airKlizz/gbert-base-germeval21-toxic-with-data-augmentation": 0.0006616413593292236,
  "ziqingyang/XLMRobertaBaseForPAWSX-en": 0.000661015510559082,
  "soham950/timelines_classifier": 0.0006608068943023682,
  "harish/EN-AStitchTask1A-BERTBaseCased-FalseFalse-0-3-BEST": 0.0006601810455322266,
  "M-FAC/bert-tiny-finetuned-stsb": 0.0006580352783203125,
  "bshlgrs/autonlp-old-data-trained-10022181": 0.0006567239761352539,
  "DoyyingFace/bert-wiki-comments-finetuned": 0.0006561279296875,
  "peril10/Pypinion": 0.0006561279296875,
  "l3cube-pune/MarathiSentiment": 0.0006556510925292969,
  "edumunozsala/RuPERTa_base_sentiment_analysis_es": 0.0006527900695800781,
  "cardiffnlp/twitter-roberta-base-irony": 0.0006527304649353027,
  "dhikri/question_answering_glue": 0.0006510019302368164,
  "korca/textfooler-roberta-base-mrpc-5": 0.0006502866744995117,
  "akahana/indonesia-emotion-roberta-small": 0.0006481409072875977,
  "gchhablani/bert-base-cased-finetuned-qnli": 0.0006477832794189453,
  "federicopascual/finetuning-sentiment-model-3000-samples-testcopy": 0.0006449893116950989,
  "prajjwal1/bert-mini-mnli": 0.0006440281867980957,
  "aditeyabaral/finetuned-sail2017-additionalpretrained-xlm-roberta-base": 0.0006412267684936523,
  "textattack/bert-base-uncased-RTE": 0.0006369352340698242,
  "ganeshkharad/gk-hinglish-sentiment": 0.0006356239318847656,
  "fadhilarkan/distilbert-base-uncased-finetuned-cola": 0.0006344318389892578,
  "daveccampbell/xlm-roberta-base-finetuned-marc-en": 0.0006337463855743408,
  "textattack/roberta-base-imdb": 0.0006315708160400391,
  "eliza-dukim/bert-base-finetuned-sts-deprecated": 0.0006291866302490234,
  "benjaminbeilharz/bert-base-uncased-dailydialog-turn-classifier": 0.0006284713745117188,
  "w11wo/javanese-roberta-small-imdb-classifier": 0.0006275996565818787,
  "korca/bae-roberta-base-mrpc": 0.000626683235168457,
  "A-bhimany-u08/bert-base-cased-qqp": 0.0006256103515625,
  "SetFit/distilbert-base-uncased__sst2__train-8-6": 0.0006254315376281738,
  "poom-sci/bert-base-uncased-multi-emotion": 0.0006227493286132812,
  "SetFit/distilbert-base-uncased__sst2__train-16-4": 0.0006222724914550781,
  "staceythompson/autonlp-new-text-classification-38319698": 0.0006222128868103027,
  "boychaboy/SNLI_bert-base-cased": 0.0006219744682312012,
  "diegorossi/distilbert-base-uncased-finetuned-sst2": 0.0006196498870849609,
  "fgaim/tiroberta-sentiment": 0.0006184577941894531,
  "ml6team/robbert-dutch-base-toxic-comments": 0.0006144046783447266,
  "Herais/pred_timeperiod": 0.0006129741668701172,
  "ysslang/autonlp-test-459011902": 0.0006127357482910156,
  "XSY/albert-base-v2-imdb-calssification": 0.000610649585723877,
  "jb2k/bert-base-multilingual-cased-language-detection": 0.0006102323532104492,
  "aXhyra/sentiment_trained_42": 0.0006085634231567383,
  "vesteinn/IceBERT-finetuned-iec-sentence": 0.0006082057952880859,
  "lvwerra/distilbert-imdb": 0.0006080269813537598,
  "spencerh/leftpartisan": 0.0006070137023925781,
  "classla/roberta-base-frenk-hate": 0.000606238842010498,
  "emrecan/bert-base-multilingual-cased-multinli_tr": 0.0006055831909179688,
  "textattack/distilbert-base-cased-SST-2": 0.0006043910980224609,
  "clem/autonlp-test3-2101782": 0.0006040334701538086,
  "TehranNLP/bert-base-uncased-mnli": 0.0006015896797180176,
  "veronica320/MPTE_disjoint_adjs_MPE_bert_200": 0.0006008148193359375,
  "aXhyra/demo_emotion_1234567": 0.0006005764007568359,
  "aXhyra/demo_emotion_31415": 0.0006005764007568359,
  "aXhyra/demo_emotion_42": 0.0006005764007568359,
  "alvp/autonlp-alberti-stanza-names-34318169": 0.0005984306335449219,
  "cointegrated/rubert-base-cased-nli-threeway": 0.0005982518196105957,
  "alperiox/autonlp-user-review-classification-536415182": 0.0005979537963867188,
  "foundkim/topic_classifier": 0.0005970299243927002,
  "IMSyPP/hate_speech_slo": 0.0005966126918792725,
  "adrianmoses/autonlp-auto-nlp-lyrics-classification-19333717": 0.000595390796661377,
  "ishan/distilbert-base-uncased-mnli": 0.0005953311920166016,
  "wrmurray/roberta-base-finetuned-imdb": 0.0005936622619628906,
  "HooshvareLab/bert-fa-base-uncased-sentiment-deepsentipers-binary": 0.0005922317504882812,
  "ttajun/nsmc_klue_01": 0.0005918741226196289,
  "kornosk/bert-election2020-twitter-stance-trump": 0.0005917251110076904,
  "CAMeL-Lab/bert-base-arabic-camelbert-mix-did-madar-corpus6": 0.0005900859832763672,
  "FabioDataGeek/distilbert-base-uncased-finetuned-emotion": 0.0005894899368286133,
  "kurianbenoy/distilbert-base-uncased-finetuned-imdb": 0.00058746337890625,
  "SetFit/distilbert-base-uncased__subj__train-8-3": 0.0005862712860107422,
  "boychaboy/MNLI_distilbert-base-uncased": 0.0005859136581420898,
  "baykenney/bert-base-gpt2detector-topk40": 0.0005855858325958252,
  "Hate-speech-CNERG/dehatebert-mono-spanish": 0.000583648681640625,
  "ksmcg/name": 0.0005830526351928711,
  "Luyu/bert-base-mdoc-bm25": 0.0005804896354675293,
  "GeniusVoice/bot-selector": 0.00058022141456604,
  "chgk13/tiny_russian_toxic_bert": 0.0005763322114944458,
  "larskjeldgaard/senda": 0.0005746558308601379,
  "pin/senda": 0.0005746558308601379,
  "unideeplearning/polibert_sa": 0.0005745887756347656,
  "jwuthri/autonlp-shipping_status_2-27366103": 0.0005741119384765625,
  "TehranNLP-org/bert-base-uncased-qqp-2e-5-42": 0.0005731582641601562,
  "aychang/distilbert-base-cased-trec-coarse": 0.0005717277526855469,
  "JonatanGk/roberta-base-ca-finetuned-hate-speech-offensive-catalan": 0.000571131706237793,
  "m3hrdadfi/albert-fa-base-v2-sentiment-snappfood": 0.0005708932876586914,
  "harish/EN-AStitchTask1A-BERTBaseCased-TrueTrue-0-3-BEST": 0.0005699396133422852,
  "MutazYoune/Absa_AspectSentiment_hotels": 0.0005693435668945312,
  "addy88/argument-classifier": 0.0005693435668945312,
  "chkla/roberta-argument": 0.0005693435668945312,
  "rafaelm47labs/spanishnews-classification": 0.000568687915802002,
  "Elron/bleurt-tiny-512": 0.0005675554275512695,
  "EasthShin/Emotion-Classification-bert-base": 0.0005664229393005371,
  "yoshitomo-matsubara/bert-base-uncased-rte": 0.0005651712417602539,
  "HooshvareLab/bert-fa-base-uncased-clf-digimag": 0.0005650520324707031,
  "kornosk/bert-election2020-twitter-stance-biden-KE-MLM": 0.0005646347999572754,
  "vittoriomaggio/bert-base-msmarco-fiqa-transfer": 0.0005638003349304199,
  "vuiseng9/bert-mnli": 0.0005621910095214844,
  "philschmid/pt-tblard-tf-allocine": 0.0005610212683677673,
  "anindabitm/sagemaker-distilbert-emotion": 0.0005609989166259766,
  "cointegrated/rubert-tiny-sentiment-balanced": 0.0005557835102081299,
  "SetFit/distilbert-base-uncased__sst2__train-32-4": 0.0005556941032409668,
  "cmarkea/distilcamembert-base-sentiment": 0.0005552470684051514,
  "arjuntheprogrammer/distilbert-base-multilingual-cased-sentiment-2": 0.0005551576614379883,
  "marcelcastrobr/sagemaker-distilbert-emotion": 0.0005545616149902344,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-0": 0.0005544424057006836,
  "cointegrated/rubert-tiny-bilingual-nli": 0.0005544424057006836,
  "tillfurger/twitter-sent": 0.0005539059638977051,
  "emfa/danish-bert-botxo-danish-finetuned-hatespeech": 0.000553131103515625,
  "lschneidpro/distilbert_uncased_imdb": 0.0005514621734619141,
  "emrecan/distilbert-base-turkish-cased-snli_tr": 0.0005497485399246216,
  "juliensimon/autonlp-imdb-demo-hf-16622775": 0.0005481243133544922,
  "lumalik/vent-roberta-emotion": 0.0005457401275634766,
  "caioamb/bert-base-uncased-finetuned-md": 0.0005447864532470703,
  "mohsenfayyaz/bert-base-uncased-offenseval2019-unbalanced": 0.0005440711975097656,
  "veronica320/MPTE_random_MPE_bert_100": 0.0005431057652458549,
  "CouchCat/ma_sa_v7_distil": 0.0005417168140411377,
  "IMSyPP/hate_speech_en": 0.0005412101745605469,
  "j-hartmann/emotion-english-distilroberta-base": 0.0005398355424404144,
  "ebrigham/my-distilcamembert-base-sentiment": 0.0005381107330322266,
  "philschmid/sagemaker-distilbert-emotion": 0.0005374401807785034,
  "Connor-tech/bert_cn_finetuning": 0.0005371570587158203,
  "techthiyanes/Bert_Bahasa_Sentiment": 0.0005371570587158203,
  "benjaminbeilharz/distilbert-dailydialog-turn-classifier": 0.0005369186401367188,
  "federicopascual/finetuned-sentiment-analysis-model": 0.0005348622798919678,
  "shokiokita/distilbert-base-uncased-finetuned-mrpc": 0.0005344152450561523,
  "ntrnghia/mrpc_vn": 0.0005335807800292969,
  "histinct7002/distilbert-base-uncased-finetuned-cola": 0.0005334019660949707,
  "moshew/BERT-miny-finetuned-clinc": 0.0005330741405487061,
  "mrm8488/codebert-base-finetuned-detect-insecure-code": 0.0005326271057128906,
  "huggingface/prunebert-base-uncased-6-finepruned-w-distil-mnli": 0.0005321502685546875,
  "finiteautomata/beto-headlines-sentiment-analysis": 0.000529170036315918,
  "moshew/tiny-bert-aug-sst2-distilled": 0.0005289316177368164,
  "victen/distilbert-base-uncased-finetuned-emotion": 0.0005265474319458008,
  "boychaboy/MNLI_roberta-base": 0.0005221366882324219,
  "fjluque/roberta-base-bne-finetuned-amazon_reviews_multi": 0.0005208402872085571,
  "M-FAC/bert-mini-finetuned-stsb": 0.0005192756652832031,
  "marcolatella/Hps_seed1": 0.0005178451538085938,
  "kangnichaluo/mnli-cb": 0.0005151033401489258,
  "yoshitomo-matsubara/bert-base-uncased-sst2_from_bert-large-uncased-sst2": 0.0005140304565429688,
  "CNT-UPenn/Bio_ClinicalBERT_for_seizureFreedom_classification": 0.0005134344100952148,
  "sgugger/distilbert-base-uncased-finetuned-cola": 0.0005104541778564453,
  "mjtaheri11/test-zarebin-2": 0.0005102306604385376,
  "lysandre/dum": 0.0005096197128295898,
  "aditeyabaral/finetuned-iitp_pdt_review-roberta-base": 0.0005066990852355957,
  "NYTK/sentiment-hts2-hubert-hungarian": 0.0005061030387878418,
  "aristotletan/scim-distillbert": 0.0005052685737609863,
  "Ridas/finetuned-emotion-26-01": 0.0005047321319580078,
  "Davlan/naija-twitter-sentiment-afriberta-large": 0.0005037188529968262,
  "elozano/bert-base-cased-fake-news": 0.0005028247833251953,
  "textattack/bert-base-uncased-imdb": 0.0005027055740356445,
  "moshew/BERT-tiny-distilled-clinc": 0.0005018711090087891,
  "tobiaslee/roberta-base-defteval-t6-st3": 0.0005017518997192383,
  "castorini/monobert-large-msmarco-finetune-only": 0.0005016326904296875,
  "aristotletan/sc-distilbert": 0.0005007386207580566,
  "kangnichaluo/mnli-4": 0.0005006790161132812,
  "dennlinger/bert-wiki-paragraphs": 0.0004999041557312012,
  "howey/bert-base-uncased-mrpc": 0.0004998445510864258,
  "Cameron/BERT-mdgender-convai-binary": 0.0004992485046386719,
  "emrecan/bert-base-turkish-cased-multinli_tr": 0.0004991292953491211,
  "aXhyra/irony_trained": 0.0004975795745849609,
  "emrecan/distilbert-base-turkish-cased-multinli_tr": 0.0004975795745849609,
  "SetFit/distilbert-base-uncased__sst2__train-32-0": 0.0004971027374267578,
  "textattack/distilbert-base-uncased-SST-2": 0.0004952512681484222,
  "abhishek/autonlp-imdb_sentiment_classification-31154": 0.0004943609237670898,
  "mrm8488/distilroberta-finetuned-age_news-classification": 0.0004943609237670898,
  "sismetanin/rubert-ru-sentiment-liniscrowd": 0.0004923641681671143,
  "Rifky/IndoBERT-FakeNews": 0.000490725040435791,
  "kangnichaluo/mnli-2": 0.0004904270172119141,
  "deepset/gbert-base-germandpr-reranking": 0.00048661231994628906,
  "DTAI-KULeuven/mbert-corona-tweets-belgium-topics": 0.0004863739013671875,
  "lewtun/roberta-base-bne-finetuned-amazon_reviews_multi-finetuned-amazon_reviews_multi": 0.00048542022705078125,
  "Andranik/TestPytorchClassification": 0.0004845559597015381,
  "huwendeng/distilroberta_b": 0.00048279762268066406,
  "umangchaudhry/distilbert-magazine-classifier": 0.00048235245048999786,
  "Jorgeutd/bert-base-uncased-ade-Ade-corpus-v2": 0.0004805326461791992,
  "Hate-speech-CNERG/dehatebert-mono-portugese": 0.0004800558090209961,
  "oliverguhr/german-sentiment-bert": 0.0004794597625732422,
  "anirudh21/distilbert-base-uncased-finetuned-mrpc": 0.0004770606756210327,
  "JaviBJ/sagemaker-distilbert-emotion": 0.000476837158203125,
  "aXhyra/test_emotion_trained_test": 0.0004755556583404541,
  "yoshitomo-matsubara/bert-base-uncased-mrpc": 0.0004749894142150879,
  "kinit/slovakbert-sentiment-twitter": 0.0004737377166748047,
  "tasosk/distilbert-base-uncased-airlines": 0.00047147274017333984,
  "howey/bert-base-uncased-cola": 0.0004709213972091675,
  "V3RX2000/distilbert-base-uncased-finetuned-cola": 0.0004703998565673828,
  "boronbrown48/wangchanberta-topic-classification": 0.00046887993812561035,
  "liuchenyang33/bert_cn_finetuning": 0.00046694278717041016,
  "MoritzLaurer/MiniLM-L6-mnli-binary": 0.00046671926975250244,
  "masapasa/sagemaker-distilbert-emotion": 0.00046634674072265625,
  "wgpubs/session-4-imdb-model": 0.0004652738571166992,
  "Sebb/german-nli-base-thesis": 0.0004652440547943115,
  "barissayil/bert-sentiment-analysis-sst": 0.00046509504318237305,
  "aviator-neural/bert-base-uncased-sst2": 0.00046265125274658203,
  "textattack/bert-base-uncased-QQP": 0.0004622936248779297,
  "M-FAC/bert-tiny-finetuned-sst2": 0.00046133995056152344,
  "marcolatella/hate_trained": 0.00046062469482421875,
  "pablouribe/bertstem-copus-supercategories": 0.00046062469482421875,
  "aXhyra/irony_trained_31415": 0.0004582405090332031,
  "avneet/distilbert-base-uncased-finetuned-cola": 0.00045809149742126465,
  "krlng/sts-GBERT-cross-encoder": 0.0004551112651824951,
  "lewtun/bert-base-uncased-finetuned-boolq": 0.0004538595676422119,
  "moshew/BERT-tiny-finetuned-clinc": 0.0004519335925579071,
  "rexxar96/autonlp-sentiment-analysis-456211724": 0.00045049190521240234,
  "SparkBeyond/roberta-large-sts-b": 0.00044989585876464844,
  "Intel/bert-base-uncased-mnli-sparse-70-unstructured": 0.0004489198327064514,
  "DoyyingFace/bert-COVID-HATE-finetuned-test": 0.00044739246368408203,
  "TehranNLP-org/bert-base-uncased-mrpc-2e-5-42": 0.00044482946395874023,
  "mishig/my-awesome-model": 0.0004429817199707031,
  "textattack/distilbert-base-uncased-MNLI": 0.00044143199920654297,
  "ragarwal/args-me-crossencoder-v1": 0.0004399418830871582,
  "aXhyra/sentiment_trained_31415": 0.0004398822784423828,
  "textattack/bert-base-uncased-SST-2": 0.0004398822784423828,
  "ajrae/bert-base-uncased-finetuned-cola": 0.00043976306915283203,
  "DSI/TweetBasedSA": 0.00043773651123046875,
  "Katsiaryna/stsb-TinyBERT-L-4-finetuned_auc_151221-top1": 0.00043773651123046875,
  "ASCCCCCCCC/distilbert-base-uncased-finetuned-clinc": 0.0004377216100692749,
  "abhishek/autonlp-imdb_eval-71421": 0.0004374980926513672,
  "blanchefort/rubert-base-cased-sentiment-rusentiment": 0.0004373788833618164,
  "mohsenfayyaz/distilbert-fa-description-classifier": 0.00043714046478271484,
  "vicd/sentiment": 0.0004366636276245117,
  "tasosk/bert-base-uncased-airlines": 0.0004364326596260071,
  "Fauzan/autonlp-judulberita-32517788": 0.00043505430221557617,
  "Kien/distilbert-base-uncased-finetuned-cola": 0.00043469667434692383,
  "Hyeon/distilbert-base-uncased-finetuned-cola": 0.00043404102325439453,
  "hackertec/roberta-base-bne-finetuned-amazon_reviews_multi-taller": 0.00043404102325439453,
  "EhsanAghazadeh/bert-based-uncased-sst2-e4": 0.00043392181396484375,
  "Alireza1044/albert-base-v2-rte": 0.00043332576751708984,
  "rohanrajpal/bert-base-en-es-codemix-cased": 0.0004328489303588867,
  "SkolkovoInstitute/russian_toxicity_classifier": 0.00043129920959472656,
  "Tahsin/distilbert-base-uncased-finetuned-emotion": 0.0004259943962097168,
  "bitsanlp/distilbert-base-uncased-finetuned-emotion": 0.0004258155822753906,
  "veronica320/MPTE_MPE_bert_all": 0.00042557716369628906,
  "sylviachency/distilbert-base-uncased-finetuned-cola": 0.00042552873492240906,
  "Tommy930/distilbert-base-uncased-finetuned-emotion": 0.0004245638847351074,
  "philschmid/distilbert-base-multilingual-cased-sentiment": 0.00042438507080078125,
  "andi611/distilbert-base-uncased-qa-boolq": 0.00042426586151123047,
  "nateraw/bert-base-uncased-ag-news": 0.0004241466522216797,
  "federicopascual/finetuning-sentiment-model-3000-samples": 0.0004235208034515381,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-8-5": 0.0004216432571411133,
  "youngfan918/bert_cn_finetuning": 0.00042057037353515625,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-4": 0.0004203915596008301,
  "federicopascual/finetuning-sentiment-analysis-model-3000-samples": 0.000420338474214077,
  "textattack/bert-base-uncased-QNLI": 0.00041961669921875,
  "Sahajtomar/German_Zeroshot": 0.0004190206527709961,
  "mohsenfayyaz/bert-base-uncased-offenseval2019-downsample": 0.0004183650016784668,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-32-8": 0.0004166469443589449,
  "boychaboy/MNLI_distilroberta-base": 0.00041663646697998047,
  "EhsanAghazadeh/bert-based-uncased-sst2-e5": 0.0004165172576904297,
  "marcolatella/emotion_trained_42": 0.0004156827926635742,
  "textattack/albert-base-v2-WNLI": 0.00041522085666656494,
  "HooshvareLab/bert-fa-base-uncased-sentiment-snappfood": 0.0004138946533203125,
  "textattack/distilbert-base-cased-MRPC": 0.00041325390338897705,
  "SCORE/claim3b-distilbert-base-uncased": 0.0004131495952606201,
  "Eugenia/roberta-base-bne-finetuned-amazon_reviews_multi": 0.00041294097900390625,
  "pmthangk09/bert-base-uncased-superglue-multirc": 0.00041291117668151855,
  "Osiris/emotion_classifier": 0.0004125833511352539,
  "ahmedrachid/FinancialBERT-Sentiment-Analysis": 0.0004115104675292969,
  "Hate-speech-CNERG/dehatebert-mono-indonesian": 0.00040969252586364746,
  "socialmediaie/TRAC2020_IBEN_B_bert-base-multilingual-uncased": 0.00040912628173828125,
  "howey/bert-base-uncased-boolq": 0.0004080533981323242,
  "chrommium/rubert-base-cased-sentence-finetuned-sent_in_ru": 0.00040721893310546875,
  "jonc/distilbert-base-uncased-finetuned-emotion": 0.0004065185785293579,
  "researchaccount/sa_sub2": 0.0004050731658935547,
  "Parsa/BBB_prediction_classification_SMILES": 0.0004049241542816162,
  "sismetanin/rubert_conversational-ru-sentiment-liniscrowd": 0.00040459632873535156,
  "TehranNLP-org/bert-base-uncased-avg-mnli-2e-5-21": 0.000402301549911499,
  "marcolatella/irony_trained": 0.00040221214294433594,
  "hadxu/distilbert-base-uncased-finetuned-emotion": 0.0004010498523712158,
  "HooshvareLab/bert-fa-base-uncased-sentiment-digikala": 0.0003992617130279541,
  "timtarusov/distilbert-base-uncased-finetuned-emotion": 0.0003992319107055664,
  "kornosk/bert-election2020-twitter-stance-trump-KE-MLM": 0.0003991955891251564,
  "Prompsit/paraphrase-roberta-es": 0.0003979206085205078,
  "DeepPavlov/roberta-large-winogrande": 0.00039780139923095703,
  "mattmcclean/distilbert-base-uncased-finetuned-emotion": 0.0003972649574279785,
  "howey/bert-base-uncased-stsb": 0.00039708614349365234,
  "Ruizhou/bert-base-uncased-finetuned-cola": 0.00039696693420410156,
  "philschmid/BERT-tweet-eval-emotion": 0.00039643049240112305,
  "textattack/bert-base-uncased-MRPC": 0.0003960132598876953,
  "cross-encoder/stsb-roberta-base": 0.000394284725189209,
  "uer/roberta-base-finetuned-jd-binary-chinese": 0.0003940761089324951,
  "sismetanin/rubert_conversational-ru-sentiment-rutweetcorp": 0.0003933906555175781,
  "Riad/finetuned-bert-mrpc": 0.00039201974868774414,
  "jambo/marker-associations-snp-binary-base": 0.00039196014404296875,
  "yacov/yacov-athena-DistilBertSC": 0.0003910064697265625,
  "Jihyun22/bert-base-finetuned-nli": 0.00038933753967285156,
  "socialmediaie/TRAC2020_ENG_C_bert-base-uncased": 0.00038909912109375,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-32-4": 0.0003876686096191406,
  "DaNLP/da-bert-hatespeech-classification": 0.00038611888885498047,
  "harish/EN-AStitchTask1A-BERTBaseCased-FalseTrue-0-3-BEST": 0.0003846585750579834,
  "yoshitomo-matsubara/bert-base-uncased-mrpc_from_bert-large-uncased-mrpc": 0.0003840923309326172,
  "RecordedFuture/Swedish-Sentiment-Fear": 0.00038313865661621094,
  "banri/distilbert-base-uncased-finetuned-cola": 0.00038307905197143555,
  "MoritzLaurer/MiniLM-L6-mnli": 0.000382840633392334,
  "hugo/secret-project-all-1": 0.0003827810287475586,
  "bozelosp/sent-sci-irrelevance": 0.00038170814514160156,
  "cmarkea/distilcamembert-base-nli": 0.00038111209869384766,
  "ml6team/distilbert-base-german-cased-toxic-comments": 0.00038111209869384766,
  "NYTK/sentiment-hts2-xlm-roberta-hungarian": 0.0003795623779296875,
  "MilaNLProc/feel-it-italian-emotion": 0.0003794431686401367,
  "pmthangk09/bert-base-uncased-glue-cola": 0.00037869811058044434,
  "socialmediaie/TRAC2020_ENG_A_bert-base-uncased": 0.0003769397735595703,
  "mollypak/roberta-model-full": 0.0003764629364013672,
  "blizrys/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext-finetuned-pubmedqa": 0.00037091970443725586,
  "Tejas3/distillbert_base_uncased_80_equal": 0.0003705024719238281,
  "Fan-s/reddit-tc-bert": 0.00037020444869995117,
  "EnsarEmirali/distilbert-base-uncased-finetuned-emotion": 0.00036966800689697266,
  "veronica320/MPTE_disjoint_adjs_MPE_bert_100": 0.0003693923354148865,
  "juliensimon/autonlp-song-lyrics-18753423": 0.0003674030303955078,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-8-3": 0.0003664446994662285,
  "ASCCCCCCCC/bert-base-chinese-finetuned-amazon_zh": 0.0003657341003417969,
  "aXhyra/irony_trained_1234567": 0.0003650188446044922,
  "philschmid/distilbert-base-multilingual-cased-sentiment-2": 0.0003647804260253906,
  "textattack/distilbert-base-cased-CoLA": 0.0003643631935119629,
  "dennlinger/roberta-cls-consec": 0.00036203861236572266,
  "philschmid/tiny-bert-sst2-distilled": 0.0003612041473388672,
  "baykenney/bert-base-gpt2detector-random": 0.00036081671714782715,
  "Alireza1044/albert-base-v2-wnli": 0.0003606826066970825,
  "18811449050/bert_cn_finetuning": 0.0003597736358642578,
  "JovenPai/bert_cn_finetunning": 0.0003597736358642578,
  "chihao/bert_cn_finetuning": 0.0003597736358642578,
  "liangxiaoxiao/bert_cn_finetuning": 0.0003597736358642578,
  "qingtan007/bert_cn_finetuning": 0.0003597736358642578,
  "song/bert_cn_finetuning": 0.0003597736358642578,
  "tk3879110/bert_cn_finetuning": 0.0003597736358642578,
  "jambo/microsoftBio-renet": 0.00035953521728515625,
  "Lazaro97/results": 0.0003592967987060547,
  "TehranNLP-org/bert-base-uncased-avg-sst2-2e-5-42": 0.0003592967987060547,
  "jason9693/SoongsilBERT-base-beep": 0.0003592967987060547,
  "hectorcotelo/autonlp-spanish_songs-202661": 0.00035829097032546997,
  "yoshitomo-matsubara/bert-base-uncased-stsb_from_bert-large-uncased-stsb": 0.00035262107849121094,
  "yaoyinnan/roberta-fakeddit": 0.00035202503204345703,
  "SetFit/distilbert-base-uncased__sst2__train-32-1": 0.00034874677658081055,
  "joeddav/distilbert-base-uncased-agnews-student": 0.00034593045711517334,
  "mfuntowicz/bert-base-cased-finetuned-sst2": 0.0003390312194824219,
  "korca/textfooler-roberta-base-sst2": 0.00033855438232421875,
  "marcolatella/hate_trained_31415": 0.0003368854522705078,
  "benjaminbeilharz/bert-base-uncased-sentiment-classifier": 0.0003368258476257324,
  "cardiffnlp/twitter-roberta-base-sentiment": 0.0003351569175720215,
  "jacobduncan00/hackMIT-finetuned-sst2": 0.00033462047576904297,
  "howey/bert-base-uncased-kaggle": 0.0003331899642944336,
  "EhsanAghazadeh/xlm-roberta-base-lcc-en-fa-2e-5-42": 0.00033211708068847656,
  "Katsiaryna/stsb-TinyBERT-L-4-finetuned_auc_161221-top3": 0.000331878662109375,
  "CAMeL-Lab/bert-base-arabic-camelbert-mix-sentiment": 0.00033164024353027344,
  "ds198799/autonlp-predict_ROI_1-29797722": 0.00033164024353027344,
  "CleveGreen/FieldClassifier": 0.00033064186573028564,
  "sgugger/finetuned-bert": 0.0003304481506347656,
  "abdelkader/distilbert-base-uncased-finetuned-emotion": 0.00033038854598999023,
  "Tejas3/distillbert_110_uncased_movie_genre": 0.00032711029052734375,
  "TehranNLP-org/bert-base-uncased-avg-cola-2e-5-63": 0.0003269314765930176,
  "howey/bert-base-uncased-mnli": 0.0003261268138885498,
  "mollypak/distilbert-base-uncased-finetuned-cola": 0.0003260374069213867,
  "sgugger/finetuned-bert-mrpc": 0.00032579898834228516,
  "HooshvareLab/bert-fa-base-uncased-sentiment-deepsentipers-multi": 0.0003235340118408203,
  "SetFit/distilbert-base-uncased__subj__train-8-4": 0.0003211498260498047,
  "blizrys/biobert-base-cased-v1.1-finetuned-pubmedqa": 0.00032061338424682617,
  "abhishek/autonlp-imdb-roberta-base-3662644": 0.0003198385238647461,
  "mlkorra/obgv-gender-bert-hi-en": 0.000319063663482666,
  "z3c1f4/distilbert-base-uncased-finetuned-cola": 0.00031703710556030273,
  "ishan/bert-base-uncased-mnli": 0.000315837562084198,
  "jambo/marker-associations-binary-base": 0.00031280517578125,
  "baykenney/bert-large-gpt2detector-topk40": 0.00031238794326782227,
  "SetFit/distilbert-base-uncased__sst2__train-16-3": 0.0003113746643066406,
  "bergum/xtremedistil-emotion": 0.00030991435050964355,
  "JonatanGk/roberta-base-bne-finetuned-hate-speech-offensive-spanish": 0.00030690431594848633,
  "Wikidepia/sponsordet": 0.00030684471130371094,
  "wangyuwei/bert_finetuning_test": 0.00030517578125,
  "pedropei/aspect-level-certainty": 0.00030332431197166443,
  "textattack/bert-base-uncased-WNLI": 0.00030216947197914124,
  "airKlizz/xlm-roberta-base-germeval21-toxic-with-task-specific-pretraining-and-data-augmentation": 0.00030162185430526733,
  "vuiseng9/bert-base-uncased-mnli": 0.0003007650375366211,
  "savasy/TurkQP": 0.00029855966567993164,
  "M-FAC/bert-tiny-finetuned-mrpc": 0.0002981424331665039,
  "blizrys/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext-finetuned-pubmedqa-1": 0.0002981126308441162,
  "sarraf/distilbert-base-uncased-finetuned-cola": 0.00029662251472473145,
  "CLTL/icf-levels-adm": 0.0002949237823486328,
  "yoshitomo-matsubara/bert-base-uncased-qnli": 0.00029456615447998047,
  "SetFit/distilbert-base-uncased__subj__all-train": 0.00029391050338745117,
  "vladenisov/sports-antihate": 0.00029218196868896484,
  "Theivaprakasham/sentence-transformers-msmarco-distilbert-base-tas-b-twitter_sentiment": 0.0002919435501098633,
  "am4nsolanki/autonlp-text-hateful-memes-36789092": 0.0002898573875427246,
  "toasterboy/TESDFEEEE": 0.00028824806213378906,
  "w11wo/javanese-distilbert-small-imdb-classifier": 0.0002880990505218506,
  "cardiffnlp/twitter-roberta-base-stance-feminist": 0.00028774142265319824,
  "younes9/AI-DAY-distilbert-base-uncased-finetuned-cola": 0.0002875328063964844,
  "baihaisheng/bert_finetuning_test": 0.000287473201751709,
  "bhadresh-savani/distilbert-base-uncased-sentiment-sst2": 0.00028586387634277344,
  "annafavaro/bert-base-uncased-finetuned-addresso": 0.0002846717834472656,
  "socialmediaie/TRAC2020_IBEN_C_bert-base-multilingual-uncased": 0.00028383731842041016,
  "Dandara/bertimbau-socioambiental": 0.0002816915512084961,
  "s87204/distilbert-base-uncased-finetuned-cola": 0.0002810359001159668,
  "sgugger/my-finetuned-bert-mprc": 0.00027996301651000977,
  "conversify/response-score": 0.0002777576446533203,
  "gilf/english-yelp-sentiment": 0.000276440754532814,
  "mofawzy/bert-labr-unbalanced": 0.0002759397029876709,
  "textattack/bert-base-cased-STS-B": 0.00027555227279663086,
  "notentered/roberta-large-finetuned-cola": 0.0002747774124145508,
  "sefaozalpadl/stop_the_steal_relevancy_analysis-binary": 0.0002726316452026367,
  "Prompsit/paraphrase-bert-pt": 0.00027239322662353516,
  "Adi2K/Priv-Consent": 0.00027000904083251953,
  "SetFit/distilbert-base-uncased__sst2__train-8-5": 0.0002690553665161133,
  "cardiffnlp/twitter-roberta-base-stance-hillary": 0.00026875734329223633,
  "liam168/c4-zh-distilbert-base-uncased": 0.00026857852935791016,
  "cardiffnlp/twitter-roberta-base-stance-abortion": 0.0002684593200683594,
  "candra/indo-headline-similarity": 0.00026726722717285156,
  "korca/bae-roberta-base-rte": 0.00026702880859375,
  "mvonwyl/roberta-twitter-spam-classifier": 0.00026702880859375,
  "ryancallihan/roberta-twitter-spam-classifier": 0.00026702880859375,
  "ageron/distilbert-emotion": 0.0002645254135131836,
  "akshara23/distilbert-base-uncased-finetuned-cola": 0.00026416778564453125,
  "Maha/OGBV-gender-twtrobertabase-en-trac1": 0.0002630949020385742,
  "korca/textfooler-roberta-base-rte": 0.00026282668113708496,
  "Maxinstellar/outputs": 0.0002612471580505371,
  "SetFit/distilbert-base-uncased__sst2__train-32-3": 0.00025853514671325684,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-32-9": 0.00025719404220581055,
  "socialmediaie/TRAC2020_HIN_C_bert-base-multilingual-uncased": 0.0002560615539550781,
  "blizrys/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext-finetuned-pubmedqa-2": 0.00025600194931030273,
  "anirudh21/bert-base-uncased-finetuned-mrpc": 0.00025576353073120117,
  "morenolq/SumTO_FNS2020": 0.00025391578674316406,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-32-3": 0.0002535581588745117,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-32-6": 0.0002529621124267578,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-32-5": 0.00025138258934020996,
  "shivangi/MRPC_output": 0.00025022029876708984,
  "cambridgeltl/trans-encoder-cross-simcse-bert-base": 0.0002500899136066437,
  "Tejas3/distillbert_110_uncased_v1": 0.00024884939193725586,
  "Sakil/distilbert_lazylearner_hatespeech_detection": 0.0002486705780029297,
  "prajjwal1/bert-tiny-mnli": 0.00024759769439697266,
  "ASCCCCCCCC/bert-base-chinese-finetuned-amazon_zh_20000": 0.0002474784851074219,
  "bhadresh-savani/distilbert-base-uncased-go-emotion": 0.00024729594588279724,
  "anirudh21/distilbert-base-uncased-finetuned-qnli": 0.00024647824466228485,
  "TehranNLP-org/bert-base-uncased-avg-cola-2e-5-21": 0.0002444777637720108,
  "zhc/distilbert-base-uncased-finetuned-mrpc-test": 0.00024434924125671387,
  "kingla6/distilbert-magazine-classifier": 0.00024363398551940918,
  "serenay/autonlp-Emotion-14722565": 0.00024259090423583984,
  "pedropei/question-intimacy": 0.00024168193340301514,
  "mollypak/bert-multilingual-base": 0.00023663043975830078,
  "boychaboy/SNLI_distilroberta-base": 0.00023651123046875,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-8-6": 0.00023567676544189453,
  "AnjanBiswas/distilbert-base-uncased-finetuned-emotion": 0.00023543834686279297,
  "xiongjie/face-expression-ja": 0.00023317337036132812,
  "aloxatel/9WT": 0.00023043155670166016,
  "anirudh21/distilbert-base-uncased-finetuned-rte": 0.0002285875380039215,
  "seanbenhur/MuLTiGENBiaS": 0.000228196382522583,
  "harish/PT-UP-mBERT-TrueTrue-0_2_BEST": 0.00022688508033752441,
  "eliza-dukim/bert-base-finetuned-sts": 0.0002263188362121582,
  "bshlgrs/autonlp-classification-9522090": 0.0002262592315673828,
  "SetFit/distilbert-base-uncased__tweet_eval_stance__all-train": 0.00022411346435546875,
  "severo/autonlp-sentiment_detection-1781580": 0.0002238154411315918,
  "shahrukhx01/bert-multitask-query-classifiers": 0.00022366642951965332,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-32-0": 0.0002219676971435547,
  "techthiyanes/chinese_sentiment": 0.00022146105766296387,
  "uer/roberta-base-finetuned-jd-full-chinese": 0.00022146105766296387,
  "textattack/distilbert-base-uncased-rotten-tomatoes": 0.00022137165069580078,
  "bella/bert_finetuning_test": 0.00022095441818237305,
  "mollypak/twitter-roberta-base-sentiment-cardiff": 0.00021696090698242188,
  "danlou/distilbert-base-uncased-finetuned-rte": 0.00021547451615333557,
  "muhtasham/autonlp-Doctor_DE-24595544": 0.0002149343490600586,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-8-8": 0.00021469593048095703,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-7": 0.00021255016326904297,
  "howey/bert-base-uncased-rte": 0.0002110712230205536,
  "moussaKam/frugalscore_medium_bert-base_bert-score": 0.00020956993103027344,
  "ttajun/bert_nm30k_posneg01": 0.00020688772201538086,
  "moussaKam/frugalscore_medium_bert-base_mover-score": 0.00020521879196166992,
  "SkolkovoInstitute/rubert-base-corruption-detector": 0.00020509958267211914,
  "maximedb/paws-x-all": 0.0002047419548034668,
  "clem/autonlp-test3-2101787": 0.00020295381546020508,
  "dexhrestha/Nepali-DistilBERT": 0.0002009272575378418,
  "yoshitomo-matsubara/bert-base-uncased-stsb": 0.00020062923431396484,
  "harish/PT-mbert-train-from-test-and-dev-SHORT-FalseTrue-0_2_BEST": 0.00019973516464233398,
  "pablouribe/bertstem-copus-presenting": 0.00019931793212890625,
  "sismetanin/rubert_conversational-ru-sentiment-krnd": 0.00019860267639160156,
  "SCORE/claim3a-distilbert-base-uncased": 0.00019763410091400146,
  "deepset/bert-base-german-cased-hatespeech-GermEval18Coarse": 0.00019538402557373047,
  "hassanzadeh/test_model": 0.00019377470016479492,
  "jwa018/norwegian_parliament": 0.00019216537475585938,
  "Hate-speech-CNERG/dehatebert-mono-french": 0.0001919865608215332,
  "aditeyabaral/finetuned-iitp_pdt_review-additionalpretrained-roberta-base": 0.0001919567584991455,
  "SetFit/distilbert-base-uncased__sst2__train-32-2": 0.00018900632858276367,
  "ruiqi-zhong/roberta-base-meta-tuning-test": 0.00018894672393798828,
  "DeadBeast/emoBERTTamil": 0.00018674135208129883,
  "aditeyabaral/finetuned-iitp_pdt_review-additionalpretrained-bert-base-cased": 0.00018668174743652344,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-1": 0.0001865476369857788,
  "ZiweiG/ziwei-bertimdb-prob": 0.00018644332885742188,
  "textattack/distilbert-base-uncased-MRPC": 0.00018570572137832642,
  "JonatanGk/roberta-base-ca-finetuned-catalonia-independence-detector": 0.00018554925918579102,
  "cross-encoder/stsb-distilroberta-base": 0.00018465518951416016,
  "airKlizz/gbert-base-germeval21-toxic": 0.00018419232219457626,
  "aXhyra/sentiment_temp": 0.0001828521490097046,
  "clampert/multilingual-sentiment-covid19": 0.0001825392246246338,
  "NDugar/finetuned-bert-mrpc": 0.00018197298049926758,
  "SetFit/distilbert-base-uncased__sst5__all-train": 0.00018197298049926758,
  "SetFit/distilbert-base-uncased__sst2__train-32-7": 0.00017777085304260254,
  "kamivao/autonlp-entity_selection-5771228": 0.0001774430274963379,
  "salesken/query_wellformedness_score": 0.00017729401588439941,
  "emrecan/bert-base-turkish-cased-allnli_tr": 0.000176943838596344,
  "SetFit/distilbert-base-uncased__sst2__train-32-5": 0.00017480552196502686,
  "Maha/hin-trac1_fin": 0.00017468631267547607,
  "pmthangk09/bert-base-uncased-esnli": 0.00017468631267547607,
  "ldacunto/distilbert-base-uncased-finetuned-cola": 0.00017334520816802979,
  "mmcquade11/autonlp-imdb-test-21134453": 0.0001732856035232544,
  "mrm8488/bert-base-german-dbmdz-cased-finetuned-pawsx-de": 0.00017198920249938965,
  "Pkrawczak/distilbert-base-uncased-finetuned-cola": 0.00017182528972625732,
  "textattack/roberta-base-CoLA": 0.0001710355281829834,
  "blizrys/biobert-v1.1-finetuned-pubmedqa": 0.00016862154006958008,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-2": 0.00016473233699798584,
  "sukhendrasingh/finetuning-sentiment-model-3000-samples": 0.0001643151044845581,
  "vittoriomaggio/msmarco-distilbert-base-v2-fiqa": 0.00016282591968774796,
  "TehranNLP/bert-base-cased-mnli": 0.0001590251922607422,
  "aditeyabaral/finetuned-iitp_pdt_review-distilbert-base-cased": 0.00015881657600402832,
  "MoritzLaurer/MiniLM-L6-mnli-fever-docnli-ling-2c": 0.00015752576291561127,
  "seanbenhur/tanglish-offensive-language-identification": 0.0001567751169204712,
  "lighteternal/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext-finetuned-mnli": 0.00015544891357421875,
  "Kao/samyarn-bert-base-multilingual-cased": 0.00015440583229064941,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-3": 0.00015357136726379395,
  "astarostap/autonlp-antisemitism-2-21194454": 0.00015343725681304932,
  "yoshitomo-matsubara/bert-base-uncased-rte_from_bert-large-uncased-rte": 0.00015297532081604004,
  "shivangi/MRPC_64_128_output": 0.00015014410018920898,
  "M-FAC/bert-mini-finetuned-qnli": 0.00014828145503997803,
  "aditeyabaral/finetuned-iitp_pdt_review-additionalpretrained-distilbert-base-cased": 0.00014709681272506714,
  "gchhablani/bert-base-cased-finetuned-wnli": 0.00014454126358032227,
  "jpreilly123/emojify_mvp": 0.00014278292655944824,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-16-9": 0.00012998655438423157,
  "SetFit/distilbert-base-uncased__sst2__train-16-2": 0.0001283586025238037,
  "AnonymousSub/cline-s10-AR": 0.00011749565601348877,
  "SetFit/distilbert-base-uncased__sst2__train-16-5": 0.00011699646711349487,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-8-0": 0.00011423509567975998,
  "nchervyakov/super-model": 0.00010970328003168106,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-32-1": 0.00010949373245239258,
  "ASCCCCCCCC/PENGMENGJIE-finetuned-emotion": 0.00010763108730316162,
  "SetFit/distilbert-base-uncased__hate_speech_offensive__train-8-9": 0.00010758638381958008,
  "Katsiaryna/stsb-TinyBERT-L-4-finetuned_auc_151221-normal": 0.00010552816092967987,
  "AnonymousSub/cline-emanuals-s10-AR": 0.00010473374277353287
}